{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30dda05f",
   "metadata": {},
   "source": [
    "# Matrix Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9685fe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import re, string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import unidecode\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# import from script\n",
    "from preprocessing_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "453215ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for city_1, city_2 in city_link:\n",
    "#     print(f\"{city_1}, {city_2}, ({city_link[(city_1, city_2)]})\")\n",
    "#     count += 1\n",
    "#     if count > 20:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98b9af4",
   "metadata": {},
   "source": [
    "## Create Language Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4001fd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'fr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed1aca90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cities dataframe\n",
    "fp = '../input/List_of_cities_300k.csv' # path to csv with city information\n",
    "cities = pd.read_csv(fp, sep=';')\n",
    "name_col = f'Mua_{language}'\n",
    "\n",
    "# list of complete city names\n",
    "city_l = [unidecode.unidecode(city) for city in cities[name_col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a9dd5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "indir = f'../../../data/'\n",
    "language = 'fr' # ['fr', 'en']\n",
    "inputfp = os.path.join(indir, f'{language}wiki/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eea7171f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../data/frwiki/frwikidump_ms5.csv\n",
      "../../../data/frwiki/frwikidump_ms4.csv\n",
      "../../../data/frwiki/frwikidump_ms6.csv\n",
      "../../../data/frwiki/frwikidump_ms7.csv\n",
      "../../../data/frwiki/frwikidump_ms3.csv\n",
      "../../../data/frwiki/frwikidump_ms2.csv\n",
      "../../../data/frwiki/frwikidump_ms1.csv\n",
      "../../../data/frwiki/frwikidump_ms9.csv\n",
      "../../../data/frwiki/frwikidump_ms8.csv\n",
      "../../../data/frwiki/frwikidump_ms11.csv\n",
      "../../../data/frwiki/frwikidump_ms10.csv\n",
      "../../../data/frwiki/frwikidump_ms12.csv\n",
      "../../../data/frwiki/frwikidump_ms13.csv\n"
     ]
    }
   ],
   "source": [
    "#- loop over .csv files create dataframes\n",
    "df = pd.DataFrame(columns = ['article_id', 'title', 'text'])\n",
    "# iterate over directory for each file path, create a dataframe\n",
    "for file in os.listdir(inputfp):\n",
    "    fp = os.path.join(inputfp, file)\n",
    "    print(fp)\n",
    "    df_temp = pd.read_csv(fp)\n",
    "    df = pd.concat([df, df_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f3b211d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(274318, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "668c1dbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2977301</td>\n",
       "      <td>Antoine Marie Philippe Asinari de Saint-Marsan</td>\n",
       "      <td>\\nAntoine Marie Philippe Asinari de Saint-Mars...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2977313</td>\n",
       "      <td>Anne de Montafie</td>\n",
       "      <td>\\nAnne de Montafie\\n\\nAnne de Montafie, comtes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2977316</td>\n",
       "      <td>Grand Siecle (histoire de France)</td>\n",
       "      <td>\\nGrand Siecle (histoire de France)\\n\\nLe term...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2977365</td>\n",
       "      <td>Alessandro Benedetti</td>\n",
       "      <td>\\nAlessandro Benedetti\\n\\nAlessandro Benedetti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2977409</td>\n",
       "      <td>Institut wallon de formation en alternance et ...</td>\n",
       "      <td>\\nInstitut wallon de formation en alternance e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  article_id                                              title  \\\n",
       "0    2977301     Antoine Marie Philippe Asinari de Saint-Marsan   \n",
       "1    2977313                                   Anne de Montafie   \n",
       "2    2977316                  Grand Siecle (histoire de France)   \n",
       "3    2977365                               Alessandro Benedetti   \n",
       "4    2977409  Institut wallon de formation en alternance et ...   \n",
       "\n",
       "                                                text  \n",
       "0  \\nAntoine Marie Philippe Asinari de Saint-Mars...  \n",
       "1  \\nAnne de Montafie\\n\\nAnne de Montafie, comtes...  \n",
       "2  \\nGrand Siecle (histoire de France)\\n\\nLe term...  \n",
       "3  \\nAlessandro Benedetti\\n\\nAlessandro Benedetti...  \n",
       "4  \\nInstitut wallon de formation en alternance e...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4486c273",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "french_matrix = process_corpus(df.text, city_l)\n",
    "\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(f\"It took {total}s to process the corpus.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1599e138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save french matrix\n",
    "outdir = \"../output/\"\n",
    "filename = \"french_matrix_20220523.csv\"\n",
    "\n",
    "def write_matrix(matrix, outdir, filename): \n",
    "    outfp = os.path.join(outdir, filename)\n",
    "    \n",
    "    if os.path.exists(outfp):\n",
    "        print(f\"File {outfp} already exists.\")\n",
    "        print(\"Are you sure you want to continue and overwrite the file?\")\n",
    "        decision = input('Continue? [y/n]')\n",
    "        if decision == 'y':\n",
    "            df.to_csv(outputfp, index = True)\n",
    "            print(f\"Matrix has been written to: {outfp}\")\n",
    "        elif decision == 'n': \n",
    "            print(\"The process has been halted.\")\n",
    "        else:\n",
    "            print(\"You did not enter a valid option.\\nThe process has halted.\")\n",
    "    else:\n",
    "        df.to_csv(outputfp, index = True)\n",
    "        print(f\"Matrix has been written to: {outfp}\")\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b2a019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create french city_link dictionary\n",
    "citylink_fr = create_citylink(french_matrix)\n",
    "\n",
    "# create df based on this dictionary\n",
    "dictionary = citylink_fr\n",
    "\n",
    "city_pairs = pd.DataFrame(columns = [\"city1\", \"city2\", \"co-occurence\"])\n",
    "i = 0\n",
    "for element1, element2 in dictionary: \n",
    "    city_pairs[[\"city1\", \"city2\", \"co-occurence\"]][i] = element1, element2, citylink_fr[(element1, element2)]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c1f8e6",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6ae2472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_city_dict(city_list):\n",
    "    \"\"\"function that creates a dictionary of name variants to the standard form\"\"\"\n",
    "    \n",
    "    city_dict = dict()\n",
    "    for city in city_list:\n",
    "        keys = city.split('-')\n",
    "        for key in keys:\n",
    "            city_dict[key] = city\n",
    "            \n",
    "    return city_dict\n",
    "\n",
    "def city_matrix(city_list):\n",
    "    matrix = np.zeros((len(city_list), len(city_list)))\n",
    "    matrix = pd.DataFrame(matrix, columns = city_list)\n",
    "    matrix['index'] = city_list\n",
    "    matrix.set_index('index', inplace = True)\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f558f9",
   "metadata": {},
   "source": [
    "## Matrix\n",
    "\n",
    "- loop over .csv files create dataframes\n",
    "- split df.text into paragraph lists\n",
    "- loop over paragraph lists with window\n",
    "- (tokenize here)\n",
    "- count occurences of cities within window\n",
    "- create co-occurences based on occurences\n",
    "\n",
    "- trial with 10 cities on like 1 ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537766d1",
   "metadata": {},
   "source": [
    "<font color='red'>IF THE TEXT IS TOKENIZED BEFORE DOING THE CITY COMPARISON THAN MULTIPLE WORD CITIES WILL NOT BE FOUND!!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d93b6455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for paragraph in processed_paragraph:\n",
    "def city_appearance(text, dictionary):\n",
    "    \n",
    "    # instantiate empty list of standardised city names and city name variations\n",
    "    cities_variants = []\n",
    "    cities_standard = []\n",
    "    # for each word in the text check if the word is a key word in the dictionary(one of the variants)\n",
    "    for word in dictionary:\n",
    "        pattern = r\"\\b\" + word + r\"\\b\" #add word boundaries to dictionary word\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            cities_variants.append(word)\n",
    "            \n",
    "    # for each word in the variant replace name with the standard form\n",
    "    for city in cities_variants:\n",
    "        city_standard = city.replace(city, dictionary[city])\n",
    "        cities_standard.append(city_standard)\n",
    "    \n",
    "    return cities_variants, cities_standard        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "38772e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - split df.text into paragraph lists\n",
    "# for each article in the dataframe create list of paragraphs\n",
    "\n",
    "\n",
    "\n",
    "def process_article(article, dictionary, matrix):\n",
    "    paragraphs = article.splitlines()\n",
    "    for paragraph in paragraphs:\n",
    "        if not paragraph:\n",
    "            continue\n",
    "    \n",
    "        cities_variants, cities_standard = city_appearance(paragraph, dictionary)\n",
    "\n",
    "        if len(set(cities_standard)) < 2: \n",
    "            continue\n",
    "            \n",
    "        else: \n",
    "            # create the co-occurences that appear\n",
    "            for city_i in cities_standard:\n",
    "                for city_j in cities_standard:\n",
    "                    if city_i != city_j: \n",
    "                        matrix.at[city_i, city_j] += 1\n",
    "            \n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d17da8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_corpus(corpus, city_list): \n",
    "    \"\"\"function that processes the entire corpus and creates co-occurence matrix\"\"\"\n",
    "    \n",
    "    dictionary = create_city_dict(city_list)\n",
    "    matrix = city_matrix(city_list)\n",
    "    \n",
    "    for article in corpus:\n",
    "        process_article(article, dictionary, matrix)\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "46d91667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 176.7749147415161s to process the corpus.\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "new_matrix = process_corpus(df.text, city_l)\n",
    "\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(f\"It took {total}s to process the corpus.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "94f1626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create city_links on the basis of matrix\n",
    "    # loop on basis of tongjing's code\n",
    "\n",
    "def create_citylink(matrix): \n",
    "    city_link = {}\n",
    "    for i in range(len(matrix)-1):\n",
    "        for j in range(i+1, len(matrix)-1):\n",
    "            city_link[(matrix.index[i], matrix.columns[j])] = matrix.iloc[i,j]\n",
    "    return city_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c6a86094",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # - loop over paragraph lists with window\n",
    "# window = 2\n",
    "# ls = ['hello', 'goodbye', 'never again'] # should be para list\n",
    "# for n in range(len(ls)-window +1): \n",
    "#     print(ls[n:n+window])\n",
    "#     # here combine the two paragraphs together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155fc4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - count occurences of cities within window\n",
    "# count city_name in paragraph_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd4732c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - create co-occurences based on occurences\n",
    "# cooccurence[citya_cityb] = max(count(city_a), count(city_b)) only if city_a !=city_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704b2cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - trial with 10 cities on like 1 ms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
