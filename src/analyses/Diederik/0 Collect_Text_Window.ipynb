{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3d8a6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3e3eacec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install nltk\n",
    "# !pip install ipywidgets==7.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6a7aa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings that can be changed\n",
    "BASEFOLDER = '../../../../data/enwiki_extracted/'\n",
    "# corpus_name = 'city_matrix.csv'\n",
    "# new_corpus = False\n",
    "\n",
    "cities_df = pd.read_csv(f'../../input/List_of_cities_300k.csv', delimiter=';')\n",
    "\n",
    "window_size = 0 # Set to Paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73c3f7e",
   "metadata": {},
   "source": [
    "# Change these (three) variables if you want to process more cities!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "617ecaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../../../../enwiki_city_pairs/biggest_cities_30/'\n",
    "updated_nr_of_cities = 30 # by population numbers\n",
    "current_nr_of_cities = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb8b2006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['athens',\n",
       " 'barcelona',\n",
       " 'berlin',\n",
       " 'birmingham',\n",
       " 'brussels',\n",
       " 'bucharest',\n",
       " 'budapest',\n",
       " 'cologne',\n",
       " 'copenhagen',\n",
       " 'frankfurt',\n",
       " 'glasgow',\n",
       " 'hamburg',\n",
       " 'katowice',\n",
       " 'lisbon',\n",
       " 'london',\n",
       " 'lyon',\n",
       " 'madrid',\n",
       " 'manchester',\n",
       " 'milan',\n",
       " 'munich',\n",
       " 'naples',\n",
       " 'paris',\n",
       " 'prague',\n",
       " 'rome',\n",
       " 'stockholm',\n",
       " 'stuttgart',\n",
       " 'turin',\n",
       " 'valencia',\n",
       " 'vienna',\n",
       " 'warsaw']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_list_of_cities = list(cities_df['Mua_en'][0:updated_nr_of_cities].str.lower())\n",
    "updated_city_pairs = list(combinations(updated_list_of_cities, 2))\n",
    "sorted(updated_list_of_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71a4e9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_list_of_cities = list(cities_df['Mua_en'][0:current_nr_of_cities].str.lower())\n",
    "current_city_pairs = list(combinations(current_list_of_cities, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a165202b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding '10' cities --> From 20 to 30 cities.\n",
      "Adding '245' city pairs --> From 190 to 435 city pairs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# len(list(combinations([x for x in range(200)], 2))) Shows number of city pairs\n",
    "print(f'''Adding '{updated_nr_of_cities-current_nr_of_cities}' cities --> From {current_nr_of_cities} to {updated_nr_of_cities} cities.\n",
    "Adding '{len(updated_city_pairs)-len(current_city_pairs)}' city pairs --> From {len(current_city_pairs)} to {len(updated_city_pairs)} city pairs.\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5396964d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CITY_PAIRS = [item for item in updated_city_pairs if item not in current_city_pairs]\n",
    "len(CITY_PAIRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b8da428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0c79f1509c5475b9463d81085c2ab4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from ipywidgets import Output\n",
    "from IPython.display import display\n",
    "out = Output()\n",
    "display(out)\n",
    "\n",
    "import sys\n",
    "tokenizer = RegexpTokenizer('\\w+')\n",
    "\n",
    "def process_wikidump(basefolder=BASEFOLDER,\n",
    "                city_pairs = CITY_PAIRS):\n",
    "\n",
    "    warnings.simplefilter('ignore')\n",
    "    folders = [f.path for f in os.scandir(basefolder) if f.is_dir()]\n",
    "    i = 0\n",
    "    for folder in tqdm(folders, total=len(folders), leave=True, desc='Folders'):\n",
    "        i+=1\n",
    "        subfolders = [ f.path for f in os.scandir(folder) if f.is_dir()]\n",
    "        for subfolder in tqdm(subfolders, total=len(subfolders), leave=False, desc='Sub Folders'):\n",
    "            if '_V4' in subfolder:\n",
    "                continue\n",
    "\n",
    "            for file in os.listdir(subfolder): # tqdm(os.listdir(subfolder), total=len(os.listdir(subfolder)), leave=True, desc='Text Files'):                            \n",
    "                with open(os.path.join(subfolder, file), \"r\", encoding=\"utf-8\") as f:\n",
    "                    process_file(file, f.read(), city_pairs) \n",
    "                with out:\n",
    "                    print(subfolder)\n",
    "                    clear_output(wait=True)\n",
    "\n",
    "            os.replace(subfolder, subfolder + '_V4')\n",
    "\n",
    "        if i == 10:\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "def process_file(filename, file_content, city_pairs):\n",
    "    articles = file_content.split('</doc>')\n",
    "    articles = [x.strip() for x in articles if len(x.strip())]\n",
    "    \n",
    "    for article in articles:\n",
    "        for paragraph in article.split('\\n'):\n",
    "            tokenized_paragraph = tokenizer.tokenize(paragraph.lower())\n",
    "        \n",
    "            word_count = Counter(tokenized_paragraph)\n",
    "            words = set(word_count.keys())\n",
    "            \n",
    "            for city_pair in city_pairs:\n",
    "                detected_cities = words.intersection(set(city_pair))\n",
    "\n",
    "                if len(detected_cities) == 2:\n",
    "                    reg_str = \"title=\\\"\" + \"(.*?)\" + \"\\\"\"\n",
    "                    title = re.findall(reg_str, article)\n",
    "\n",
    "                    reg_str = \"id=\\\"\" + \"(.*?)\" + \"\\\"\"\n",
    "                    article_id = re.findall(reg_str, article)\n",
    "                    \n",
    "                    with out:\n",
    "                        print('\\r',filename,\" || \", \"title: \", title[0], \" || \", \"citypair: \", city_pair, end='                                            ')\n",
    "\n",
    "                    content = f'title=\"{title[0]}\", id={article_id[0]} \\n{paragraph} \\n\\n'\n",
    "\n",
    "                    textfile = f'{OUTPUT_FOLDER}{city_pair[0]}_{city_pair[1]}.txt'\n",
    "\n",
    "                    with open(textfile, 'a+', encoding='utf-16') as f:\n",
    "                        f.writelines(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "002bdaaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are you sure you want to collect window text of 20 cities? (currently: '10' cities).\n",
      "Type 'Yes' to continue.n\n",
      "\n",
      "Canceling Operation...\n",
      "\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 964 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "protection = input(f\"Are you sure you want to collect window text of {updated_nr_of_cities} cities? (currently: '{current_nr_of_cities}' cities).\\nType 'Yes' to continue.\")\n",
    "\n",
    "if protection == 'Yes':\n",
    "    print()\n",
    "    t = 5\n",
    "    while t:\n",
    "        print(f\"\\rcontinuing processing in {t}...\", end=\"\")\n",
    "        t -= 1\n",
    "        time.sleep(1)\n",
    "    clear_output()\n",
    "    # process_wikidump(basefolder=BASEFOLDER, city_pairs=CITY_PAIRS)\n",
    "else:\n",
    "    print(\"\\nCanceling Operation...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfc49d0",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<hr>\n",
    "<hr>\n",
    "<hr>\n",
    "<hr>\n",
    "<hr>\n",
    "<hr>\n",
    "<hr>\n",
    "<!-- <br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br> -->\n",
    "<div style=\"height: 500px;\"></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
