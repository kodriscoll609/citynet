{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e6222a2",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightgreen; border-radius: 5px; padding: 10px;\">\n",
    "    <h4>Word Embedding Categorisation</h4>\n",
    "    <p>...</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba24f61",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2acb2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_functions import *\n",
    "from word_embedding_functions import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572bfe58",
   "metadata": {},
   "source": [
    "- Clean and preprocess (lemmatise) a list of documents (e.g. paragraphs)\n",
    "- Get your topics through unsupervised clustering with (LDA Topic Modeling)\n",
    "- Use these for the word embedding algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24cead3",
   "metadata": {},
   "source": [
    "### 1. Set Topic Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ce2990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing words with double meaning helps (e.g. bear, degree)\n",
    "\n",
    "#fashion_words = ['fashion', 'model', 'vogue', 'store', 'designer', 'couture', 'catwalk', 'runway', 'modeling', 'clothing', 'cosmetic', 'brand', 'retail', 'advertising', 'perfume']\n",
    "diplomacy_words = ['War', 'Embassy', 'Army', 'Diplomatic', 'Ambassador', 'Treaty', 'Protest', 'Force', 'Mission', 'Arrest', 'Government', 'Police', 'Attack', 'Party', 'Minister']\n",
    "entertainment_words = ['Opera', 'Festival', 'Perform', 'Orchestra', 'Symphony', 'Concert', 'Music', 'Film', 'Sing', 'Theatre', 'Performance', 'Role', 'Premiere', 'Tour', 'Band']\n",
    "art_words = ['Exhibition', 'Art', 'Museum', 'Gallery', 'Exhibit', 'Painting', 'Collection', 'Paint', 'Portrait', 'Artist', 'Sculpture', 'Fashion', 'Design', 'Contemporary', 'Painter']\n",
    "education_words = ['Study', 'School', 'Professor', 'University', 'Graduate', 'Educate', 'Lecture', 'Research', 'College', 'Teach', 'Science', 'Education', 'Philosophy', 'Doctorate', 'Faculty'] # replaced bear with educate and degree with Lecture\n",
    "transportation_words = ['Railway', 'Route', 'Line', 'Operate', 'Flight', 'Station', 'Service', 'Airline', 'Airport', 'Train', 'Passenger', 'Speed', 'Aircraft', 'Rail', 'Network']\n",
    "sport_words = ['Final', 'Win', 'Team', 'Match', 'Game', 'Goal', 'Club', 'League', 'Champion', 'Championship', 'Season', 'Score', 'Round', 'Tournament', 'Football']\n",
    "\n",
    "lda_topic_words = { #'fashion': fashion_words,\n",
    "                    'diplomacy': diplomacy_words,\n",
    "                   'entertainment': entertainment_words,\n",
    "                   'art': art_words,\n",
    "                   # 'education': education_words,\n",
    "                   'transportation': transportation_words,\n",
    "                   'sport': sport_words}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7acd430",
   "metadata": {},
   "source": [
    "### 2. Loading GloVe Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3b8c87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This will take approximately ~ 4 minutes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3a3bd2b39584263ae4cfd3969d7d847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2196017 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 2s\n",
      "Wall time: 3min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "embeddings_dict, discarded_dict = load_glove_word_embeddings(GLOVE_PATH=\"../../../../../glove.840B.300d.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b381a8",
   "metadata": {},
   "source": [
    "### 3. Get Mean of the words from each Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a006cfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vectors_dict = {}\n",
    "for topic in lda_topic_words:\n",
    "    words = lda_topic_words[topic]\n",
    "    words = [word for word in words if word in embeddings_dict.keys()] # checks if word is in vocabulary (i.e. has been seen by the model before)\n",
    "    mean_embedding = np.mean([embeddings_dict[word.lower()] for word in words], axis=0)\n",
    "    mean_vectors_dict[topic] = mean_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e451b05",
   "metadata": {},
   "source": [
    "### 4. Load Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2794ca81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "# df = pd.read_csv(\"../../../../../data/clean/classified_435_citypairs_311k_paragraphs.csv\")\n",
    "df = pd.read_csv(\"../../../../../data/clean/classified_50cities_740citypairs_400k_paragraphs.csv\")\n",
    "df['merged_POS'] = df['merged_POS'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "205028da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "df2 = pd.read_csv(\"../../../../../data/clean/classified_435_citypairs_311k_paragraphs.csv\")\n",
    "df2['merged_POS'] = df2['merged_POS'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f931d81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['paragraph_id', 'city_pair', 'paragraph', 'merged_POS', 'lda_sport',\n",
       "       'lda_art', 'lda_entertainment', 'lda_diplomacy', 'lda_transportation',\n",
       "       'lda_education', 'lda_dominant', 'lda_dominant_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1838671",
   "metadata": {},
   "source": [
    "### Select number of paragraphs to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a7cef080",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df2[:20000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4471c8",
   "metadata": {},
   "source": [
    "### 5. Classify Paragraphs (by Word Embedding Algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c65deda",
   "metadata": {},
   "source": [
    "#### 5.1 Select right parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "77d77c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_threshold = 0.20\n",
    "verbose1 = False\n",
    "verbose2 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d9d2ba63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "562d9537c0d9438ab2d9e012be46f6f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "topics = [key for key in list(sorted(mean_vectors_dict.keys()))]\n",
    "nested_l = [['index']+topics+['embedding_dominant']]\n",
    "\n",
    "for idx, row in tqdm(sample['merged_POS'].iteritems(), total=len(sample['merged_POS'])):\n",
    "    output = categorize_text(lemmatized_wordlist=row, mean_vectors_dict=mean_vectors_dict, keywords=topics, embeddings_dict=embeddings_dict, bottom_threshold=bottom_threshold, verbose1=verbose1, verbose2=verbose2)\n",
    "    \n",
    "    temp_l = [idx] +[result[1] for result in output['category_similarities']] + [output['prediction']]\n",
    "    \n",
    "    #print(row, output['category_similarities'])\n",
    "    \n",
    "    if len(nested_l[0]) != len(temp_l):\n",
    "        raise Exception('Not the same size!')\n",
    "        \n",
    "    nested_l.append(temp_l)\n",
    "\n",
    "\n",
    "prediction_df = pd.DataFrame(nested_l[1:],columns=nested_l[0]).set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61a1d113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>art</th>\n",
       "      <th>diplomacy</th>\n",
       "      <th>entertainment</th>\n",
       "      <th>sport</th>\n",
       "      <th>transportation</th>\n",
       "      <th>embedding_dominant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.326078</td>\n",
       "      <td>0.301628</td>\n",
       "      <td>0.768217</td>\n",
       "      <td>0.609732</td>\n",
       "      <td>diplomacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.265830</td>\n",
       "      <td>1.243361</td>\n",
       "      <td>0.322190</td>\n",
       "      <td>0.425173</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>diplomacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.893548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.217850</td>\n",
       "      <td>3.286044</td>\n",
       "      <td>transportation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.751220</td>\n",
       "      <td>0.405813</td>\n",
       "      <td>0.301628</td>\n",
       "      <td>0.752151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.335578</td>\n",
       "      <td>transportation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>0.564840</td>\n",
       "      <td>2.052759</td>\n",
       "      <td>0.235481</td>\n",
       "      <td>0.342959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>diplomacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>3.496995</td>\n",
       "      <td>0.232795</td>\n",
       "      <td>0.903156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.207021</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0.681283</td>\n",
       "      <td>2.127343</td>\n",
       "      <td>1.813117</td>\n",
       "      <td>0.498108</td>\n",
       "      <td>0.253583</td>\n",
       "      <td>diplomacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>1.605937</td>\n",
       "      <td>1.992433</td>\n",
       "      <td>2.456318</td>\n",
       "      <td>0.893511</td>\n",
       "      <td>0.211430</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.634616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.215969</td>\n",
       "      <td>diplomacy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            art  diplomacy  entertainment     sport  transportation  \\\n",
       "index                                                                 \n",
       "0      0.000000   2.326078       0.301628  0.768217        0.609732   \n",
       "1      0.265830   1.243361       0.322190  0.425173        0.000000   \n",
       "2      0.000000   0.893548       0.000000  0.217850        3.286044   \n",
       "3      0.751220   0.405813       0.301628  0.752151        0.000000   \n",
       "4      0.000000   0.000000       0.000000  0.000000        0.335578   \n",
       "...         ...        ...            ...       ...             ...   \n",
       "4995   0.564840   2.052759       0.235481  0.342959        0.000000   \n",
       "4996   3.496995   0.232795       0.903156  0.000000        0.207021   \n",
       "4997   0.681283   2.127343       1.813117  0.498108        0.253583   \n",
       "4998   1.605937   1.992433       2.456318  0.893511        0.211430   \n",
       "4999   0.000000   4.634616       0.000000  0.000000        0.215969   \n",
       "\n",
       "      embedding_dominant  \n",
       "index                     \n",
       "0              diplomacy  \n",
       "1              diplomacy  \n",
       "2         transportation  \n",
       "3                  sport  \n",
       "4         transportation  \n",
       "...                  ...  \n",
       "4995           diplomacy  \n",
       "4996                 art  \n",
       "4997           diplomacy  \n",
       "4998       entertainment  \n",
       "4999           diplomacy  \n",
       "\n",
       "[5000 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b59cea0",
   "metadata": {},
   "source": [
    "### 4. Insert classification into dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15818543",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df = sample.join(prediction_df)\n",
    "updated_df.head(2)\n",
    "updated_df['same_categorisation'] = updated_df.apply(lambda x: x.lda_dominant.endswith(x.embedding_dominant), axis=1) # (updated_df['embedding_dominant'].isin('lda_dominant') 'lda_dominant'].str.contains() == updated_df['outcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9cb1d4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df2 = sample.join(prediction_df)\n",
    "updated_df2.head(2)\n",
    "updated_df2['same_categorisation'] = (updated_df2['idxmax'].str.lower() == updated_df2['embedding_dominant'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d548807",
   "metadata": {},
   "source": [
    "#### Similarity between lda topic model and word embedding algorithm output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c3436013",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3216"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_df['same_categorisation'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "ec756955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10.0, 20.0]      611\n",
       "(20.0, 30.0]      544\n",
       "(30.0, 40.0]      426\n",
       "(-0.001, 10.0]    338\n",
       "Name: merged_POS, dtype: int64"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of lemmatised words in the paragraphs\n",
    "updated_df[(updated_df['max'] > 0.9)]['merged_POS'].str.len().value_counts(bins=[0, 10, 20, 30, 40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f751b3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idxmax          same_categorisation\n",
      "Art             True                   408\n",
      "                False                   79\n",
      "Diplomacy       True                   448\n",
      "                False                   20\n",
      "Education       False                  378\n",
      "Entertainment   True                   948\n",
      "                False                   18\n",
      "Sport           True                   168\n",
      "                False                    1\n",
      "Transportation  True                   193\n",
      "                False                   75\n",
      "Name: same_categorisation, dtype: int64\n",
      "----------------------------------------------------\n",
      "idxmax          same_categorisation\n",
      "Art             True                   0.837782\n",
      "                False                  0.162218\n",
      "Diplomacy       True                   0.957265\n",
      "                False                  0.042735\n",
      "Education       False                  1.000000\n",
      "Entertainment   True                   0.981366\n",
      "                False                  0.018634\n",
      "Sport           True                   0.994083\n",
      "                False                  0.005917\n",
      "Transportation  True                   0.720149\n",
      "                False                  0.279851\n",
      "Name: same_categorisation, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(updated_df2[(updated_df2['max'] > 0.8) & (updated_df2['merged_POS'].str.len() > 10)].groupby('idxmax')['same_categorisation'].value_counts())\n",
    "print('----------------------------------------------------')\n",
    "print(updated_df2[(updated_df2['max'] > 0.8) & (updated_df2['merged_POS'].str.len() > 10)].groupby('idxmax')['same_categorisation'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1669ade8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lda_dominant        same_categorisation\n",
      "lda_art             True                   227\n",
      "                    False                  201\n",
      "lda_diplomacy       True                   409\n",
      "                    False                    7\n",
      "lda_education       False                  413\n",
      "lda_entertainment   True                   979\n",
      "                    False                   20\n",
      "lda_sport           True                   173\n",
      "                    False                    2\n",
      "lda_transportation  True                   192\n",
      "                    False                   68\n",
      "Name: same_categorisation, dtype: int64\n",
      "----------------------------------------------------\n",
      "lda_dominant        same_categorisation\n",
      "lda_art             True                   0.530374\n",
      "                    False                  0.469626\n",
      "lda_diplomacy       True                   0.983173\n",
      "                    False                  0.016827\n",
      "lda_education       False                  1.000000\n",
      "lda_entertainment   True                   0.979980\n",
      "                    False                  0.020020\n",
      "lda_sport           True                   0.988571\n",
      "                    False                  0.011429\n",
      "lda_transportation  True                   0.738462\n",
      "                    False                  0.261538\n",
      "Name: same_categorisation, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(updated_df[(updated_df['lda_dominant_score'] > 0.8) & (updated_df['merged_POS'].str.len() > 10)].groupby('lda_dominant')['same_categorisation'].value_counts())\n",
    "print('----------------------------------------------------')\n",
    "print(updated_df[(updated_df['lda_dominant_score'] > 0.8) & (updated_df['merged_POS'].str.len() > 10)].groupby('lda_dominant')['same_categorisation'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f9724008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "art               349\n",
      "diplomacy         176\n",
      "entertainment      47\n",
      "sport              46\n",
      "transportation     14\n",
      "Name: embedding_dominant, dtype: int64\n",
      "\n",
      "art               0.552215\n",
      "diplomacy         0.278481\n",
      "entertainment     0.074367\n",
      "sport             0.072785\n",
      "transportation    0.022152\n",
      "Name: embedding_dominant, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.7\n",
    "\n",
    "print(updated_df[(updated_df['lda_dominant'] == 'lda_art') & (updated_df['lda_dominant_score'] > threshold)]['embedding_dominant'].value_counts())\n",
    "print()\n",
    "print(updated_df[(updated_df['lda_dominant'] == 'lda_art') & (updated_df['lda_dominant_score'] > threshold)]['embedding_dominant'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fc731c",
   "metadata": {},
   "source": [
    "### 5. Aggregate paragraphs Classification into City Pair Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0dfff1",
   "metadata": {},
   "source": [
    "#### 5.1 Select right parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "04f99088",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_lda_threshold = 0.9\n",
    "minimal_paragraph_length = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "55fa4999",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = updated_df[(updated_df['city_pair'].isin(updated_df['city_pair'].unique()[:])) & (updated_df['max'] > bottom_lda_threshold) & (updated_df['merged_POS'].str.len() > minimal_paragraph_length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "e23f7927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_df[temp_df['idxmax'] != 'Education']['same_categorisation'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "bf26ea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = temp_df.groupby('city_pair')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "bf577f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_list2 = [['city_pair', 'paragraphs', 'lemmatised_paragraph_length', 'same_categorisation_raw', 'same_categorisation_percentage',\n",
    "                'lda_dominant_category', 'embedding_dominant_category', 'lda_art', 'embedding_art', 'lda_diplomacy',\n",
    "                'embedding_diplomacy', 'lda_entertainment', 'embedding_entertainment', \n",
    "                'lda_sport', 'embedding_sport', 'lda_transportation', 'embedding_transportation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "a01981ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d9a632b078546219c3994ebf074b5b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "categories = topics\n",
    "for city_pair, sub_df in tqdm(grouped_df):\n",
    "    paragraph_count = sub_df['paragraph'].count()\n",
    "    same_categorisation_raw = sub_df['same_categorisation'].sum()\n",
    "    same_categorisation_percentage = sub_df['same_categorisation'].sum()/sub_df['same_categorisation'].count()\n",
    "    lemmatised_paragraph_len = sub_df['merged_POS'].str.len().mean()\n",
    "    \n",
    "    lda_prediction = sub_df['idxmax'].value_counts()\n",
    "    embedding_prediction = sub_df['outcome'].value_counts()\n",
    "        \n",
    "    lda_dominant_category = lda_prediction.idxmax()\n",
    "    embedding_dominant_category = embedding_prediction.idxmax()\n",
    "    \n",
    "    lda_prediction = lda_prediction.to_dict()\n",
    "    embedding_prediction = embedding_prediction.to_dict()\n",
    "    \n",
    "    if (len(lda_prediction) != 6) or (len(embedding_prediction) != 6):\n",
    "        for category in categories:\n",
    "            if category.capitalize() not in lda_prediction.keys():\n",
    "                lda_prediction[category.capitalize()] = 0\n",
    "            if category not in embedding_prediction.keys():\n",
    "                embedding_prediction[category] = 0\n",
    "                \n",
    "    temp_l2 = [city_pair, paragraph_count, lemmatised_paragraph_len, same_categorisation_raw, same_categorisation_percentage,\n",
    "                lda_dominant_category, embedding_dominant_category, lda_prediction['Art'], embedding_prediction['art'], lda_prediction['Diplomacy'],\n",
    "                embedding_prediction['diplomacy'],\n",
    "                lda_prediction['Entertainment'], embedding_prediction['entertainment'], lda_prediction['Sport'],\n",
    "                embedding_prediction['sport'], lda_prediction['Transportation'], embedding_prediction['transportation']]\n",
    "    if len(nested_list2[0]) != len(temp_l2):\n",
    "        raise Exception('Not the same size!')\n",
    "    \n",
    "    nested_list2.append(temp_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "bd6d9c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lda_art</th>\n",
       "      <th>embedding_art</th>\n",
       "      <th>lda_diplomacy</th>\n",
       "      <th>embedding_diplomacy</th>\n",
       "      <th>lda_entertainment</th>\n",
       "      <th>embedding_entertainment</th>\n",
       "      <th>lda_sport</th>\n",
       "      <th>embedding_sport</th>\n",
       "      <th>lda_transportation</th>\n",
       "      <th>embedding_transportation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.192771</td>\n",
       "      <td>0.174699</td>\n",
       "      <td>0.106426</td>\n",
       "      <td>0.134538</td>\n",
       "      <td>0.479920</td>\n",
       "      <td>0.481928</td>\n",
       "      <td>0.068273</td>\n",
       "      <td>0.090361</td>\n",
       "      <td>0.152610</td>\n",
       "      <td>0.118474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.237506</td>\n",
       "      <td>0.200412</td>\n",
       "      <td>0.197836</td>\n",
       "      <td>0.235446</td>\n",
       "      <td>0.381762</td>\n",
       "      <td>0.385368</td>\n",
       "      <td>0.075734</td>\n",
       "      <td>0.091705</td>\n",
       "      <td>0.107161</td>\n",
       "      <td>0.087069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lda_art  embedding_art  lda_diplomacy  embedding_diplomacy  \\\n",
       "0  0.192771       0.174699       0.106426             0.134538   \n",
       "1  0.237506       0.200412       0.197836             0.235446   \n",
       "\n",
       "   lda_entertainment  embedding_entertainment  lda_sport  embedding_sport  \\\n",
       "0           0.479920                 0.481928   0.068273         0.090361   \n",
       "1           0.381762                 0.385368   0.075734         0.091705   \n",
       "\n",
       "   lda_transportation  embedding_transportation  \n",
       "0            0.152610                  0.118474  \n",
       "1            0.107161                  0.087069  "
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.DataFrame(nested_list2[1:],columns=nested_list2[0])\n",
    "\n",
    "# Normalize category outcomes\n",
    "final_df[list(final_df.columns)[7:]].div(final_df['paragraphs'], axis=0) # .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "bd641f0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_pair</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>lemmatised_paragraph_length</th>\n",
       "      <th>same_categorisation_raw</th>\n",
       "      <th>same_categorisation_percentage</th>\n",
       "      <th>lda_dominant_category</th>\n",
       "      <th>embedding_dominant_category</th>\n",
       "      <th>lda_art</th>\n",
       "      <th>embedding_art</th>\n",
       "      <th>lda_diplomacy</th>\n",
       "      <th>embedding_diplomacy</th>\n",
       "      <th>lda_entertainment</th>\n",
       "      <th>embedding_entertainment</th>\n",
       "      <th>lda_sport</th>\n",
       "      <th>embedding_sport</th>\n",
       "      <th>lda_transportation</th>\n",
       "      <th>embedding_transportation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>berlin_milan</td>\n",
       "      <td>498</td>\n",
       "      <td>29.405622</td>\n",
       "      <td>458</td>\n",
       "      <td>0.919679</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>96</td>\n",
       "      <td>87</td>\n",
       "      <td>53</td>\n",
       "      <td>67</td>\n",
       "      <td>239</td>\n",
       "      <td>240</td>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "      <td>76</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>london_berlin</td>\n",
       "      <td>1941</td>\n",
       "      <td>32.223596</td>\n",
       "      <td>1766</td>\n",
       "      <td>0.909840</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>461</td>\n",
       "      <td>389</td>\n",
       "      <td>384</td>\n",
       "      <td>457</td>\n",
       "      <td>741</td>\n",
       "      <td>748</td>\n",
       "      <td>147</td>\n",
       "      <td>178</td>\n",
       "      <td>208</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       city_pair  paragraphs  lemmatised_paragraph_length  \\\n",
       "0   berlin_milan         498                    29.405622   \n",
       "1  london_berlin        1941                    32.223596   \n",
       "\n",
       "   same_categorisation_raw  same_categorisation_percentage  \\\n",
       "0                      458                        0.919679   \n",
       "1                     1766                        0.909840   \n",
       "\n",
       "  lda_dominant_category embedding_dominant_category  lda_art  embedding_art  \\\n",
       "0         Entertainment               entertainment       96             87   \n",
       "1         Entertainment               entertainment      461            389   \n",
       "\n",
       "   lda_diplomacy  embedding_diplomacy  lda_entertainment  \\\n",
       "0             53                   67                239   \n",
       "1            384                  457                741   \n",
       "\n",
       "   embedding_entertainment  lda_sport  embedding_sport  lda_transportation  \\\n",
       "0                      240         34               45                  76   \n",
       "1                      748        147              178                 208   \n",
       "\n",
       "   embedding_transportation  \n",
       "0                        59  \n",
       "1                       169  "
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51169d39",
   "metadata": {},
   "source": [
    "# Extras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653c794e",
   "metadata": {},
   "source": [
    "#### Show closest words to topic vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba2695ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "from preprocessing_functions import *\n",
    "\n",
    "def find_closest_embeddings(embedding, cutoff=25):\n",
    "    return sorted(embeddings_dict.keys(), key=lambda token: spatial.distance.euclidean(embeddings_dict[token], embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f92fd60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = 'art'\n",
    "\n",
    "words = find_closest_embeddings(embedding=\n",
    "     mean_vectors_dict[topic]    # embeddings_dict['diplomacy'] # embeddings_dict['fashion']\n",
    ")[:2000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec9282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_words = get_english_words(path='../../../input/english_words_alpha_370k.txt\n",
    "print(remove_non_existing_words_from_wordlist(words, english_words))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
