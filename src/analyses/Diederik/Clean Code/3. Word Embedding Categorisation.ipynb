{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b063045e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_functions import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d786469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ye\n"
     ]
    }
   ],
   "source": [
    "if isinstance(mean_embedding, np.ndarray):\n",
    "    print('ye')\n",
    "# type(mean_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c62be77",
   "metadata": {},
   "source": [
    "### Categorize_text algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "cdadc46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_text(lemmatized_wordlist, mean_vectors_dict, keywords, embeddings_dict, number_of_keywords=1, bottom_threshold=0.1, verbose1=False, verbose2=False):\n",
    "    \"\"\"\n",
    "    --> Function that loads glove word embeddings.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "            lemmatized_words: List -> List of words.\n",
    "            keywords: nested list -> List of lists of keywords that represent categories.\n",
    "            number_of_keywords: Int (default = 1) -> number of keywords to use from a category (setting it to 0 will use them all!)\n",
    "            bottom_threshold: Float (default = 0.1) -> Lowest allowed similarity value between a word and dominant category.\n",
    "            verbose1: Bool (default = False) -> Shows similarity calculations between a word and each keyword.\n",
    "            verbose2: Bool (default = False) -> Shows similarity calculations between a word and each category.\n",
    "\n",
    "    \"\"\"\n",
    "    keywords_to_use = number_of_keywords if number_of_keywords else 1000\n",
    "    similar_categories = []\n",
    "    \n",
    "    for word in lemmatized_wordlist:\n",
    "        try:\n",
    "            word_vector = embeddings_dict[word]\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        if verbose1 or verbose2:\n",
    "            print(f\"word: \\t\\t'{word}'\")\n",
    "\n",
    "        closeness = []\n",
    "\n",
    "        for category in keywords:\n",
    "            summed_similarity = 0\n",
    "            for keyword in category[:keywords_to_use]:\n",
    "                try:\n",
    "                    keyword_vector = mean_vectors_dict[keyword]\n",
    "                    # print(keyword)\n",
    "#                 if isinstance(keyword, np.ndarray):\n",
    "#                     keyword = 'Diplomacy'\n",
    "                    # keyword_vector = mean_embedding\n",
    "                except:\n",
    "                    keyword_vector = embeddings_dict[keyword]\n",
    "                \n",
    "                value = 1 - cosine(keyword_vector, word_vector)\n",
    "                summed_similarity += value\n",
    "            \n",
    "            normalized_similarity = summed_similarity/len(category[:keywords_to_use])\n",
    "            # print(type(normalized_similarity), normalized_similarity)\n",
    "            closeness.append((normalized_similarity, category[0]))\n",
    "\n",
    "            if verbose1:\n",
    "                # print('___________________________')\n",
    "                print('===>', '\\t\\tcategory:', category[0], '\\n\\t\\tsimilarity:', normalized_similarity, f\"\\n\\t\\tkeywords: {category[:keywords_to_use]}\\n\")\n",
    "\n",
    "\n",
    "        similar_category = max(closeness)\n",
    "\n",
    "        sortedcat = sorted(closeness, key=lambda item: item[0], reverse=True)\n",
    "        if (sortedcat[0][0] - 0.05) > sortedcat[2][0]:\n",
    "            allowed = True\n",
    "        else:\n",
    "            allowed = False\n",
    "\n",
    "\n",
    "\n",
    "        if similar_category[0] > bottom_threshold and allowed:\n",
    "            similar_categories.append((word, similar_category))\n",
    "            if verbose2:\n",
    "                #print('category similarity:')\n",
    "                # pprint(sorted(closeness, key=lambda x: x[0], reverse=True))\n",
    "                print(f\"choice: \\tkept\")\n",
    "                print(f\"\\n==> \\tcategory:, {similar_category[1]}, \\n\\tsimilarity score: {similar_category[0]}\")\n",
    "        elif verbose2:\n",
    "            print(f\"choice: \\tdiscarded\")\n",
    "            reason = 'ambiguity' if not allowed else 'low similarity score'\n",
    "            print(f\"reasoning: \\t{reason}\")\n",
    "\n",
    "        if verbose2:\n",
    "            # print(f\"analysis: {'not' if not allowed else ''} enough difference\\nscores:\")\n",
    "            print(\"\\nscores:\\n\\t----category----          ----score----\")\n",
    "            for i in sortedcat:\n",
    "                print(f\"\\t{i[1]:<10s} \\t\\t{i[0]}\")\n",
    "            print()\n",
    "\n",
    "            print('='*100)\n",
    "            print('')\n",
    "    \n",
    "    categories_dict = {key[0]: 0 for key in descriptive_keywords}\n",
    "    \n",
    "    for x in similar_categories:\n",
    "        categories_dict[x[1][1]] += x[1][0] #print(x[1])\n",
    "    \n",
    "\n",
    "    nonsorted_results = list(sorted(categories_dict.items(), key=lambda item: item[0], reverse=False))\n",
    "    results = list(sorted(categories_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "    #pprint(results)\n",
    "\n",
    "    # print(f\"\\nThe dominant category is: '{results[0][0]}'\", end='')\n",
    "    #if (results[0][1] - (float(results[0][1])/5)) <= results[1][1]:  \n",
    "    #    print(f\", closely followed by: '{results[1][0]}'.\")\n",
    "    if verbose2:\n",
    "        print('\\n')\n",
    "        pprint(similar_categories)\n",
    "    # print('\\n --------------------------------------------------------------------')\n",
    "    \n",
    "    prediction_dict = {'category_similarities': nonsorted_results, 'prediction': results[0][0]} \n",
    "\n",
    "    return prediction_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f939b16e",
   "metadata": {},
   "source": [
    "### Old Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69898acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict = ['war', 'fight', 'death', 'hostility', 'bomb', 'battle', 'nazi', 'army']\n",
    "politics = ['politics', 'debate', 'election', 'government', 'democracy']\n",
    "fashion = ['fashion', 'model', 'magazine', 'walk', 'glamour', 'outfit']\n",
    "culture = ['culture', 'opera', \"festival\", 'collection', 'exhibition', 'art', 'museum']\n",
    "sports = ['sport', 'medal', 'game', 'championship', 'club', 'score', 'play']\n",
    "education = ['education', 'professor', 'study', 'research', 'university']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03b3c7b",
   "metadata": {},
   "source": [
    "### New Keywords based on lda topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec69bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"\"\"1 & Study           & Railway           & Final                    \\\\\n",
    "2 & School          & Route             & Win                \\\\\n",
    "3 & Professor       & Line              & Team               \\\\\n",
    "4 & University      & Operate           & Match               \\\\\n",
    "5 & Graduate        & Flight            & Game              \\\\\n",
    "6 & Bear            & Station           & Goal          \\\\\n",
    "7 & Degree          & Service           & Club           \\\\\n",
    "8 & Research        & Airline           & League          \\\\\n",
    "9 & College         & Airport           & Champion            \\\\\n",
    "10 & Teach           & Train             & Championship       \"\"\"\n",
    "\n",
    "s2 = s.split('&')\n",
    "s3 = [''.join([i for i in x if not i.isdigit()]) for x in s2]\n",
    "s4 = [item.replace('\\\\\\n', '') for item in s3]\n",
    "s5 = [item.strip() for item in s4]\n",
    "s5.remove(s5[0])\n",
    "s5\n",
    "\n",
    "l = []\n",
    "for i in range(1, 30, 3):\n",
    "    l.append(s5[i])\n",
    "    print(s5[i])\n",
    "    \n",
    "if len(l) == 10:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a875b5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "diplomacy_words = ['War', 'Embassy', 'Army', 'Diplomatic', 'Ambassador', 'Treaty', 'Protest', 'Force', 'Mission', 'Arrest']\n",
    "entertainment_words = ['Opera', 'Festival', 'Perform', 'Orchestra', 'Symphony', 'Concert', 'Music', 'Film', 'Sing', 'Theatre']\n",
    "art_words = ['Exhibition', 'Art', 'Museum', 'Gallery', 'Exhibit', 'Painting', 'Collection', 'Paint', 'Portrait', 'Artist']\n",
    "education_words = ['Study', 'School', 'Professor', 'University', 'Graduate', 'Bear', 'Degree', 'Research', 'College', 'Teach']\n",
    "transportation_words = ['Railway', 'Route', 'Line', 'Operate', 'Flight', 'Station', 'Service', 'Airline', 'Airport', 'Train']\n",
    "sport_words = ['Final', 'Win', 'Team', 'Match', 'Game', 'Goal', 'Club', 'League', 'Champion', 'Championship']\n",
    "\n",
    "lda_topic_words = {'diplomacy': diplomacy_words,\n",
    "                   'entertainment': entertainment_words,\n",
    "                   'art': art_words,\n",
    "                   'education': education_words,\n",
    "                   'transportation': transportation_words,\n",
    "                   'sport': sport_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "315cc0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Single keywords\n",
    "# diplomacy = ['diplomacy']\n",
    "# entertainment = ['entertainment']\n",
    "# art = ['art']\n",
    "# education = ['education']\n",
    "# transportation = ['transportation']\n",
    "# sport = ['sport']\n",
    "\n",
    "# descriptive_keywords = [diplomacy, entertainment, art, education, transportation, sport]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3917d90a",
   "metadata": {},
   "source": [
    "### Get Mean of the words from each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b5aac524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diplomacy ['War', 'Embassy', 'Army', 'Diplomatic', 'Ambassador', 'Treaty', 'Protest', 'Force', 'Mission', 'Arrest']\n",
      "entertainment ['Opera', 'Festival', 'Perform', 'Orchestra', 'Symphony', 'Concert', 'Music', 'Film', 'Sing', 'Theatre']\n",
      "art ['Exhibition', 'Art', 'Museum', 'Gallery', 'Exhibit', 'Painting', 'Collection', 'Paint', 'Portrait', 'Artist']\n",
      "education ['Study', 'School', 'Professor', 'University', 'Graduate', 'Bear', 'Degree', 'Research', 'College', 'Teach']\n",
      "transportation ['Railway', 'Route', 'Line', 'Operate', 'Flight', 'Station', 'Service', 'Airline', 'Airport', 'Train']\n",
      "sport ['Final', 'Win', 'Team', 'Match', 'Game', 'Goal', 'Club', 'League', 'Champion', 'Championship']\n"
     ]
    }
   ],
   "source": [
    "for x in lda_topic_words:\n",
    "    print(x, lda_topic_words[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3612ea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Word2vec instead of GloVe, should be transmutible though\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "mean_vectors_dict = {}\n",
    "for topic in lda_topic_words:\n",
    "    words = lda_topic_words[topic]\n",
    "    words = [word for word in words if word in embeddings_dict.keys()] # checks if word is in vocabulary (i.e. has been seen by the model before)\n",
    "    mean_embedding = np.mean([embeddings_dict[word] for word in words], axis=0)\n",
    "    mean_vectors_dict[topic] = mean_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc564e6e",
   "metadata": {},
   "source": [
    "- Maybe i should do word1+ word2+ word3+ ...+ ...+ ... of the top 5 most relevant words of a topic to find the cluster center?\n",
    "- Maybe get the mean embedding of multiple words? (from jveerbeek's DM page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb61c9f",
   "metadata": {},
   "source": [
    "### Loading GloVe Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "837e52b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This will take approximately ~ 4 minutes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc302a56c1d34e88af43698c9a27cfd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2196017 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". ['.', '.', '-0.1573', '-0.29517']\n",
      "at ['name@domain.com', '0.0061218', '0.39595', '-0.22079']\n",
      ". ['.', '.', '.', '.']\n",
      "to ['name@domain.com', '0.33865', '0.12698', '-0.16885']\n",
      ". ['.', '0.035974', '-0.024421', '0.71402']\n",
      ". ['.', '.', '.', '0.033459']\n",
      "email ['name@domain.com', '0.33529', '0.32949', '0.2646']\n",
      "or ['name@domain.com', '0.48374', '0.49669', '-0.25089']\n",
      "contact ['name@domain.com', '0.016426', '0.13728', '0.18781']\n",
      "Email ['name@domain.com', '0.37344', '0.024573', '-0.12583']\n",
      "on ['name@domain.com', '0.037295', '-0.15381', '-0.045189']\n",
      "At ['Killerseats.com', '-0.13854', '-0.01706', '-0.13651']\n",
      "by ['name@domain.com', '0.6882', '-0.36436', '0.62079']\n",
      "in ['mylot.com', '-0.18148', '0.47096', '0.32916']\n",
      "emailing ['name@domain.com', '0.39173', '-0.39132', '-0.4266']\n",
      "Contact ['name@domain.com', '0.14933', '-0.28605', '0.3444']\n",
      "at ['name@domain.com', '0.44321', '-0.40005', '-0.20065']\n",
      "• ['name@domain.com', '-0.13288', '-0.31383', '-0.032356']\n",
      "at ['Amazon.com', '-0.5275', '-0.73685', '0.10968']\n",
      "is ['name@domain.com', '-0.1197', '0.10706', '-0.10519']\n",
      "CPU times: total: 3min 33s\n",
      "Wall time: 3min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "embeddings_dict = load_glove_word_embeddings(GLOVE_PATH=\"../../../../../glove.840B.300d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0237c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT_DIR = \"../../../../../data/clean/city_pair_paragraphs3/\"\n",
    "# BATCHES = [5]\n",
    "# POS = [\"NOUN\", \"VERB\", \"ADJ\"]\n",
    "# ONLY_ENGLISH_WORDS = True\n",
    "# sort_by_paragraphs_count = True\n",
    "# merged_POS = True\n",
    "\n",
    "# data_list = import_lemmatised_paragraphs(INPUT_DIR, POS, BATCHES, ONLY_ENGLISH_WORDS=ONLY_ENGLISH_WORDS, merged_POS=merged_POS, sort_by_paragraphs=sort_by_paragraphs_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62edab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frames = [citypair['lemmatized_paragraphs'] for citypair in data_list]\n",
    "# citypairs = [citypair['city_pair'] for citypair in data_list]\n",
    "\n",
    "# result = pd.concat(frames) #, keys=citypairs)\n",
    "# result.set_index('paragraph_id', inplace=True)\n",
    "# result.sort_index(inplace=True)\n",
    "# result.reset_index(inplace=True)\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "05db2c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "df = pd.read_csv(\"classified_435_citypairs_311k_paragraphs.csv\")\n",
    "df['merged_POS'] = df['merged_POS'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "43f0e558",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>city_pair</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>merged_POS</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Art</th>\n",
       "      <th>Diplomacy</th>\n",
       "      <th>Entertainment</th>\n",
       "      <th>Transportation</th>\n",
       "      <th>Education</th>\n",
       "      <th>idxmax</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>berlin_milan</td>\n",
       "      <td>he signed with hc milan in 1991 and in 1992, c...</td>\n",
       "      <td>[game, year, country, flight, capital, year, s...</td>\n",
       "      <td>0.797217</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>0.004335</td>\n",
       "      <td>0.003792</td>\n",
       "      <td>0.186813</td>\n",
       "      <td>0.004139</td>\n",
       "      <td>Sport</td>\n",
       "      <td>0.797217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>berlin_milan</td>\n",
       "      <td>she received first public attention while stil...</td>\n",
       "      <td>[attention, year, best, bronze, medal, winner,...</td>\n",
       "      <td>0.956612</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>0.020074</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>0.001268</td>\n",
       "      <td>Sport</td>\n",
       "      <td>0.956612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53</td>\n",
       "      <td>berlin_milan</td>\n",
       "      <td>green's prominence grew in 1930 as he set a ne...</td>\n",
       "      <td>[prominence, world, record, km, champion, stri...</td>\n",
       "      <td>0.952881</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.043408</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>Sport</td>\n",
       "      <td>0.952881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>57</td>\n",
       "      <td>berlin_milan</td>\n",
       "      <td>in total he was the referee in 82 internationa...</td>\n",
       "      <td>[total, referee, match, international, goal, g...</td>\n",
       "      <td>0.722303</td>\n",
       "      <td>0.001365</td>\n",
       "      <td>0.249650</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>0.024076</td>\n",
       "      <td>Sport</td>\n",
       "      <td>0.722303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>berlin_milan</td>\n",
       "      <td>simon biwott (born 3 march 1970 in eldoret, ua...</td>\n",
       "      <td>[march, distance, runner, medal, man, marathon...</td>\n",
       "      <td>0.903493</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>0.002063</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>0.001559</td>\n",
       "      <td>0.089317</td>\n",
       "      <td>Sport</td>\n",
       "      <td>0.903493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310810</th>\n",
       "      <td>312669</td>\n",
       "      <td>warsaw_valencia</td>\n",
       "      <td>it would take almost 20 years before elfsborg ...</td>\n",
       "      <td>[year, cup, period, club, history, layer, cup,...</td>\n",
       "      <td>0.995711</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>Sport</td>\n",
       "      <td>0.995711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310814</th>\n",
       "      <td>312673</td>\n",
       "      <td>warsaw_valencia</td>\n",
       "      <td>on 16 september 2020, valencia returned to pol...</td>\n",
       "      <td>[loan, end, season, season, plethora, injury, ...</td>\n",
       "      <td>0.987588</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>0.002796</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.002112</td>\n",
       "      <td>0.002669</td>\n",
       "      <td>Sport</td>\n",
       "      <td>0.987588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310816</th>\n",
       "      <td>312675</td>\n",
       "      <td>warsaw_valencia</td>\n",
       "      <td>in the 2000–01 season, the team finished third...</td>\n",
       "      <td>[season, team, polish, league, cup, quarterfin...</td>\n",
       "      <td>0.928442</td>\n",
       "      <td>0.001872</td>\n",
       "      <td>0.064023</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>0.001655</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>Sport</td>\n",
       "      <td>0.928442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310817</th>\n",
       "      <td>312676</td>\n",
       "      <td>warsaw_valencia</td>\n",
       "      <td>it would take almost 20 years before elfsborg ...</td>\n",
       "      <td>[year, cup, period, club, history, layer, cup,...</td>\n",
       "      <td>0.995711</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>Sport</td>\n",
       "      <td>0.995711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310827</th>\n",
       "      <td>312686</td>\n",
       "      <td>warsaw_valencia</td>\n",
       "      <td>in october 2007, bakero joined ronald koeman's...</td>\n",
       "      <td>[teammate, staff, year, job, head, coach, team...</td>\n",
       "      <td>0.988496</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>0.002474</td>\n",
       "      <td>Sport</td>\n",
       "      <td>0.988496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32121 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        paragraph_id        city_pair  \\\n",
       "19                20     berlin_milan   \n",
       "38                39     berlin_milan   \n",
       "52                53     berlin_milan   \n",
       "56                57     berlin_milan   \n",
       "61                62     berlin_milan   \n",
       "...              ...              ...   \n",
       "310810        312669  warsaw_valencia   \n",
       "310814        312673  warsaw_valencia   \n",
       "310816        312675  warsaw_valencia   \n",
       "310817        312676  warsaw_valencia   \n",
       "310827        312686  warsaw_valencia   \n",
       "\n",
       "                                                paragraph  \\\n",
       "19      he signed with hc milan in 1991 and in 1992, c...   \n",
       "38      she received first public attention while stil...   \n",
       "52      green's prominence grew in 1930 as he set a ne...   \n",
       "56      in total he was the referee in 82 internationa...   \n",
       "61      simon biwott (born 3 march 1970 in eldoret, ua...   \n",
       "...                                                   ...   \n",
       "310810  it would take almost 20 years before elfsborg ...   \n",
       "310814  on 16 september 2020, valencia returned to pol...   \n",
       "310816  in the 2000–01 season, the team finished third...   \n",
       "310817  it would take almost 20 years before elfsborg ...   \n",
       "310827  in october 2007, bakero joined ronald koeman's...   \n",
       "\n",
       "                                               merged_POS     Sport       Art  \\\n",
       "19      [game, year, country, flight, capital, year, s...  0.797217  0.003704   \n",
       "38      [attention, year, best, bronze, medal, winner,...  0.956612  0.001135   \n",
       "52      [prominence, world, record, km, champion, stri...  0.952881  0.000861   \n",
       "56      [total, referee, match, international, goal, g...  0.722303  0.001365   \n",
       "61      [march, distance, runner, medal, man, marathon...  0.903493  0.001763   \n",
       "...                                                   ...       ...       ...   \n",
       "310810  [year, cup, period, club, history, layer, cup,...  0.995711  0.000826   \n",
       "310814  [loan, end, season, season, plethora, injury, ...  0.987588  0.002389   \n",
       "310816  [season, team, polish, league, cup, quarterfin...  0.928442  0.001872   \n",
       "310817  [year, cup, period, club, history, layer, cup,...  0.995711  0.000826   \n",
       "310827  [teammate, staff, year, job, head, coach, team...  0.988496  0.002214   \n",
       "\n",
       "        Diplomacy  Entertainment  Transportation  Education idxmax       max  \n",
       "19       0.004335       0.003792        0.186813   0.004139  Sport  0.797217  \n",
       "38       0.020074       0.019908        0.001004   0.001268  Sport  0.956612  \n",
       "52       0.001007       0.000881        0.043408   0.000962  Sport  0.952881  \n",
       "56       0.249650       0.001398        0.001207   0.024076  Sport  0.722303  \n",
       "61       0.002063       0.001805        0.001559   0.089317  Sport  0.903493  \n",
       "...           ...            ...             ...        ...    ...       ...  \n",
       "310810   0.000966       0.000845        0.000730   0.000922  Sport  0.995711  \n",
       "310814   0.002796       0.002446        0.002112   0.002669  Sport  0.987588  \n",
       "310816   0.064023       0.001916        0.001655   0.002091  Sport  0.928442  \n",
       "310817   0.000966       0.000845        0.000730   0.000922  Sport  0.995711  \n",
       "310827   0.002591       0.002267        0.001958   0.002474  Sport  0.988496  \n",
       "\n",
       "[32121 rows x 12 columns]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_confidence_df = df[df['idxmax'] == 'Sport']  # df[(df['max'] > 0.8) & (df['max'] < 0.85) & (df['idxmax'] == 'Sport')]\n",
    "high_confidence_sample = high_confidence_df\n",
    "high_confidence_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c320e8",
   "metadata": {},
   "source": [
    "### Word Embedding Algoritm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4479e53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# high_confidence_sample.merged_POS.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d497f355",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1465\n",
      "{'sport': 1445, 'entertainment': 5, 'transportation': 1, 'education': 13, 'art': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9863481228668942"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sum(predictions.values()))\n",
    "print(predictions)\n",
    "predictions['sport']/sum(predictions.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "cb387855",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['art', 'diplomacy', 'education', 'entertainment', 'sport', 'transportation']\n",
    "for category in categories:\n",
    "    df[category] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "d34a5790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>city_pair</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>merged_POS</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Art</th>\n",
       "      <th>Diplomacy</th>\n",
       "      <th>Entertainment</th>\n",
       "      <th>Transportation</th>\n",
       "      <th>Education</th>\n",
       "      <th>idxmax</th>\n",
       "      <th>max</th>\n",
       "      <th>diplomacy</th>\n",
       "      <th>entertainment</th>\n",
       "      <th>education</th>\n",
       "      <th>art</th>\n",
       "      <th>transportation</th>\n",
       "      <th>sport</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>berlin_milan</td>\n",
       "      <td>after his tenure in academia, he continued to ...</td>\n",
       "      <td>[tenure, academia, month, year, travel, incide...</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.770121</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>0.224750</td>\n",
       "      <td>Diplomacy</td>\n",
       "      <td>0.770121</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>berlin_milan</td>\n",
       "      <td>one of the astronomers selected for the search...</td>\n",
       "      <td>[astronomer, search, priest, invitation, group...</td>\n",
       "      <td>0.195772</td>\n",
       "      <td>0.498009</td>\n",
       "      <td>0.302968</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>Art</td>\n",
       "      <td>0.498009</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>berlin_milan</td>\n",
       "      <td>there are plenty of air connections between ye...</td>\n",
       "      <td>[plenty, air, connection, city, connection, ci...</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.991741</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>0.991741</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>berlin_milan</td>\n",
       "      <td>since 2009, 'the brandery', an urban fashion s...</td>\n",
       "      <td>[fashion, year, language, monitor, ranking, wo...</td>\n",
       "      <td>0.383249</td>\n",
       "      <td>0.602904</td>\n",
       "      <td>0.003862</td>\n",
       "      <td>0.003379</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.003687</td>\n",
       "      <td>Art</td>\n",
       "      <td>0.602904</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>berlin_milan</td>\n",
       "      <td>when considering the commuter belts or metropo...</td>\n",
       "      <td>[commuter, belt, area, datum, population, orde...</td>\n",
       "      <td>0.002721</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0.094386</td>\n",
       "      <td>0.005463</td>\n",
       "      <td>0.886130</td>\n",
       "      <td>0.005962</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>0.886130</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paragraph_id     city_pair  \\\n",
       "0             1  berlin_milan   \n",
       "1             2  berlin_milan   \n",
       "2             3  berlin_milan   \n",
       "3             4  berlin_milan   \n",
       "4             5  berlin_milan   \n",
       "\n",
       "                                           paragraph  \\\n",
       "0  after his tenure in academia, he continued to ...   \n",
       "1  one of the astronomers selected for the search...   \n",
       "2  there are plenty of air connections between ye...   \n",
       "3  since 2009, 'the brandery', an urban fashion s...   \n",
       "4  when considering the commuter belts or metropo...   \n",
       "\n",
       "                                          merged_POS     Sport       Art  \\\n",
       "0  [tenure, academia, month, year, travel, incide...  0.000765  0.001501   \n",
       "1  [astronomer, search, priest, invitation, group...  0.195772  0.498009   \n",
       "2  [plenty, air, connection, city, connection, ci...  0.000873  0.001713   \n",
       "3  [fashion, year, language, monitor, ranking, wo...  0.383249  0.602904   \n",
       "4  [commuter, belt, area, datum, population, orde...  0.002721  0.005337   \n",
       "\n",
       "   Diplomacy  Entertainment  Transportation  Education          idxmax  \\\n",
       "0   0.770121       0.001536        0.001327   0.224750       Diplomacy   \n",
       "1   0.302968       0.001100        0.000950   0.001201             Art   \n",
       "2   0.002005       0.001754        0.991741   0.001914  Transportation   \n",
       "3   0.003862       0.003379        0.002918   0.003687             Art   \n",
       "4   0.094386       0.005463        0.886130   0.005962  Transportation   \n",
       "\n",
       "        max diplomacy entertainment education   art transportation sport  \\\n",
       "0  0.770121      None          None      None  None           None  None   \n",
       "1  0.498009      None          None      None  None           None  None   \n",
       "2  0.991741      None          None      None  None           None  None   \n",
       "3  0.602904      None          None      None  None           None  None   \n",
       "4  0.886130      None          None      None  None           None  None   \n",
       "\n",
       "  outcome  \n",
       "0    None  \n",
       "1    None  \n",
       "2    None  \n",
       "3    None  \n",
       "4    None  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['outcome'] = None\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3fcfe9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a49a1000a4243b6a13e3fff87740107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32121 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = {}\n",
    "i = 0\n",
    "%time\n",
    "l = [['index', 'art', 'diplomacy', 'education', 'entertainment', 'sport', 'transportation', 'outcome']]\n",
    "for idx, row in tqdm(high_confidence_sample['merged_POS'].iteritems(), total=len(high_confidence_sample['merged_POS'])):\n",
    "    output = categorize_text(lemmatized_wordlist=row, mean_vectors_dict=mean_vectors_dict, keywords=[['diplomacy'], ['entertainment'], ['education'], ['art'], ['transportation'], ['sport']], embeddings_dict=embeddings_dict, number_of_keywords=1, bottom_threshold=0.25, verbose1=False, verbose2=False)\n",
    "\n",
    "    prediction = output['prediction']\n",
    "    results = output['category_similarities']\n",
    "    temp_l = [idx] +[result[1] for result in results] + [prediction]\n",
    "    l.append(temp_l)\n",
    "    \n",
    "    \n",
    "    # print(results)\n",
    "#     for category, value in results:\n",
    "#         row[category] = value\n",
    "#         #print(category, value)\n",
    "#     #print(results)\n",
    "# #     # print(results)\n",
    "# #     if False:\n",
    "# #         if prediction != 'sport':\n",
    "# #             if results[1] != 'sport':\n",
    "# #                 print(results[0], results[1], row.paragraph)\n",
    "# #     #         print(prediction, '\\n', row.paragraph, '\\n')\n",
    "\n",
    "    if (results[0][1] - results[1][1]) > 0.10:\n",
    "        if prediction not in predictions.keys():\n",
    "            predictions[prediction] = 1\n",
    "        else:\n",
    "            predictions[prediction] +=1\n",
    "            \n",
    "# print(high_confidence_sample.head())\n",
    "df4 = pd.DataFrame(l[1:],columns=l[0]).set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "66a04400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sport             31218\n",
       "education           432\n",
       "entertainment       222\n",
       "transportation      139\n",
       "diplomacy            82\n",
       "art                  28\n",
       "Name: outcome, dtype: int64"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['outcome'].value_counts()\n",
    "# 31218/df2['outcome'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "d4f00b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.join(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b90430d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e800b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"classified_435_citypairs_311k_paragraphs_both_methods.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f056001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "df['merged_POS'] = df['merged_POS'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c476e676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_counts(bin=3)\n",
    "# value_counts(bins=[0, 0.2, 0.6, 1])\n",
    "# value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be813c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>city_pair</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>merged_POS</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Art</th>\n",
       "      <th>Diplomacy</th>\n",
       "      <th>Entertainment</th>\n",
       "      <th>Transportation</th>\n",
       "      <th>Education</th>\n",
       "      <th>idxmax</th>\n",
       "      <th>max</th>\n",
       "      <th>art</th>\n",
       "      <th>diplomacy</th>\n",
       "      <th>education</th>\n",
       "      <th>entertainment</th>\n",
       "      <th>sport</th>\n",
       "      <th>transportation</th>\n",
       "      <th>outcome</th>\n",
       "      <th>same_categorisation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>543</td>\n",
       "      <td>berlin_milan</td>\n",
       "      <td>athens (greece), bangkok (thailand), berlin (g...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.013162</td>\n",
       "      <td>0.025815</td>\n",
       "      <td>0.030210</td>\n",
       "      <td>0.026428</td>\n",
       "      <td>0.449186</td>\n",
       "      <td>0.455199</td>\n",
       "      <td>Education</td>\n",
       "      <td>0.455199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>diplomacy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3835</th>\n",
       "      <td>3853</td>\n",
       "      <td>london_berlin</td>\n",
       "      <td>35 – 'wall street journal' (us): baghdad, bang...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.013162</td>\n",
       "      <td>0.452173</td>\n",
       "      <td>0.030210</td>\n",
       "      <td>0.452786</td>\n",
       "      <td>0.022827</td>\n",
       "      <td>0.028841</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>0.452786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>diplomacy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3836</th>\n",
       "      <td>3854</td>\n",
       "      <td>london_berlin</td>\n",
       "      <td>24 – 'new york times' (us): baghdad, beijing, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.439520</td>\n",
       "      <td>0.452173</td>\n",
       "      <td>0.030210</td>\n",
       "      <td>0.026428</td>\n",
       "      <td>0.022827</td>\n",
       "      <td>0.028841</td>\n",
       "      <td>Art</td>\n",
       "      <td>0.452173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>diplomacy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3837</th>\n",
       "      <td>3855</td>\n",
       "      <td>london_berlin</td>\n",
       "      <td>17 – 'washington post' (us): baghdad, beijing,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.013162</td>\n",
       "      <td>0.025815</td>\n",
       "      <td>0.456568</td>\n",
       "      <td>0.026428</td>\n",
       "      <td>0.022827</td>\n",
       "      <td>0.455199</td>\n",
       "      <td>Diplomacy</td>\n",
       "      <td>0.456568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>diplomacy</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8322</th>\n",
       "      <td>8369</td>\n",
       "      <td>london_madrid</td>\n",
       "      <td>barcelona is behind london, new york, paris, m...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.013162</td>\n",
       "      <td>0.452173</td>\n",
       "      <td>0.030210</td>\n",
       "      <td>0.026428</td>\n",
       "      <td>0.022827</td>\n",
       "      <td>0.455199</td>\n",
       "      <td>Education</td>\n",
       "      <td>0.455199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>diplomacy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303346</th>\n",
       "      <td>305170</td>\n",
       "      <td>vienna_copenhagen</td>\n",
       "      <td>united kingdom, malaysia, singapore, helsinki,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.013162</td>\n",
       "      <td>0.452173</td>\n",
       "      <td>0.456568</td>\n",
       "      <td>0.026428</td>\n",
       "      <td>0.022827</td>\n",
       "      <td>0.028841</td>\n",
       "      <td>Diplomacy</td>\n",
       "      <td>0.456568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>diplomacy</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304480</th>\n",
       "      <td>306310</td>\n",
       "      <td>vienna_frankfurt</td>\n",
       "      <td>athens (greece), bangkok (thailand), berlin (g...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.013162</td>\n",
       "      <td>0.025815</td>\n",
       "      <td>0.030210</td>\n",
       "      <td>0.026428</td>\n",
       "      <td>0.449186</td>\n",
       "      <td>0.455199</td>\n",
       "      <td>Education</td>\n",
       "      <td>0.455199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>diplomacy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306397</th>\n",
       "      <td>308234</td>\n",
       "      <td>vienna_prague</td>\n",
       "      <td>salzburg, vienna, bonn, helsinki, istanbul, at...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.013162</td>\n",
       "      <td>0.452173</td>\n",
       "      <td>0.030210</td>\n",
       "      <td>0.452786</td>\n",
       "      <td>0.022827</td>\n",
       "      <td>0.028841</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>0.452786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>diplomacy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306864</th>\n",
       "      <td>308707</td>\n",
       "      <td>vienna_prague</td>\n",
       "      <td>vienna, czech republic (prague), germany (augs...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.439520</td>\n",
       "      <td>0.025815</td>\n",
       "      <td>0.030210</td>\n",
       "      <td>0.026428</td>\n",
       "      <td>0.022827</td>\n",
       "      <td>0.455199</td>\n",
       "      <td>Education</td>\n",
       "      <td>0.455199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>diplomacy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306865</th>\n",
       "      <td>308708</td>\n",
       "      <td>vienna_prague</td>\n",
       "      <td>athens (greece), bangkok (thailand), berlin (g...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.439520</td>\n",
       "      <td>0.452173</td>\n",
       "      <td>0.030210</td>\n",
       "      <td>0.026428</td>\n",
       "      <td>0.022827</td>\n",
       "      <td>0.028841</td>\n",
       "      <td>Art</td>\n",
       "      <td>0.452173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>diplomacy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        paragraph_id          city_pair  \\\n",
       "539              543       berlin_milan   \n",
       "3835            3853      london_berlin   \n",
       "3836            3854      london_berlin   \n",
       "3837            3855      london_berlin   \n",
       "8322            8369      london_madrid   \n",
       "...              ...                ...   \n",
       "303346        305170  vienna_copenhagen   \n",
       "304480        306310   vienna_frankfurt   \n",
       "306397        308234      vienna_prague   \n",
       "306864        308707      vienna_prague   \n",
       "306865        308708      vienna_prague   \n",
       "\n",
       "                                                paragraph merged_POS  \\\n",
       "539     athens (greece), bangkok (thailand), berlin (g...         []   \n",
       "3835    35 – 'wall street journal' (us): baghdad, bang...         []   \n",
       "3836    24 – 'new york times' (us): baghdad, beijing, ...         []   \n",
       "3837    17 – 'washington post' (us): baghdad, beijing,...         []   \n",
       "8322    barcelona is behind london, new york, paris, m...         []   \n",
       "...                                                   ...        ...   \n",
       "303346  united kingdom, malaysia, singapore, helsinki,...         []   \n",
       "304480  athens (greece), bangkok (thailand), berlin (g...         []   \n",
       "306397  salzburg, vienna, bonn, helsinki, istanbul, at...         []   \n",
       "306864  vienna, czech republic (prague), germany (augs...         []   \n",
       "306865  athens (greece), bangkok (thailand), berlin (g...         []   \n",
       "\n",
       "           Sport       Art  Diplomacy  Entertainment  Transportation  \\\n",
       "539     0.013162  0.025815   0.030210       0.026428        0.449186   \n",
       "3835    0.013162  0.452173   0.030210       0.452786        0.022827   \n",
       "3836    0.439520  0.452173   0.030210       0.026428        0.022827   \n",
       "3837    0.013162  0.025815   0.456568       0.026428        0.022827   \n",
       "8322    0.013162  0.452173   0.030210       0.026428        0.022827   \n",
       "...          ...       ...        ...            ...             ...   \n",
       "303346  0.013162  0.452173   0.456568       0.026428        0.022827   \n",
       "304480  0.013162  0.025815   0.030210       0.026428        0.449186   \n",
       "306397  0.013162  0.452173   0.030210       0.452786        0.022827   \n",
       "306864  0.439520  0.025815   0.030210       0.026428        0.022827   \n",
       "306865  0.439520  0.452173   0.030210       0.026428        0.022827   \n",
       "\n",
       "        Education         idxmax       max  art  diplomacy  education  \\\n",
       "539      0.455199      Education  0.455199  0.0        0.0        0.0   \n",
       "3835     0.028841  Entertainment  0.452786  0.0        0.0        0.0   \n",
       "3836     0.028841            Art  0.452173  0.0        0.0        0.0   \n",
       "3837     0.455199      Diplomacy  0.456568  0.0        0.0        0.0   \n",
       "8322     0.455199      Education  0.455199  0.0        0.0        0.0   \n",
       "...           ...            ...       ...  ...        ...        ...   \n",
       "303346   0.028841      Diplomacy  0.456568  0.0        0.0        0.0   \n",
       "304480   0.455199      Education  0.455199  0.0        0.0        0.0   \n",
       "306397   0.028841  Entertainment  0.452786  0.0        0.0        0.0   \n",
       "306864   0.455199      Education  0.455199  0.0        0.0        0.0   \n",
       "306865   0.028841            Art  0.452173  0.0        0.0        0.0   \n",
       "\n",
       "        entertainment  sport  transportation    outcome  same_categorisation  \n",
       "539               0.0    0.0             0.0  diplomacy                False  \n",
       "3835              0.0    0.0             0.0  diplomacy                False  \n",
       "3836              0.0    0.0             0.0  diplomacy                False  \n",
       "3837              0.0    0.0             0.0  diplomacy                 True  \n",
       "8322              0.0    0.0             0.0  diplomacy                False  \n",
       "...               ...    ...             ...        ...                  ...  \n",
       "303346            0.0    0.0             0.0  diplomacy                 True  \n",
       "304480            0.0    0.0             0.0  diplomacy                False  \n",
       "306397            0.0    0.0             0.0  diplomacy                False  \n",
       "306864            0.0    0.0             0.0  diplomacy                False  \n",
       "306865            0.0    0.0             0.0  diplomacy                False  \n",
       "\n",
       "[202 rows x 20 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['merged_POS'].str.len() == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66e2740f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.001, 20.0]    102021\n",
       "(20.0, 40.0]      117620\n",
       "(40.0, 60.0]       55029\n",
       "(60.0, 80.0]       21332\n",
       "(80.0, 100.0]       8646\n",
       "(100.0, 120.0]      3190\n",
       "(120.0, 140.0]      1573\n",
       "(140.0, 160.0]       670\n",
       "(160.0, 180.0]       307\n",
       "(180.0, 200.0]       169\n",
       "Name: merged_POS, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['merged_POS'].str.len().value_counts(bins=[0, 20, 40, 60, 80, 100, 120, 140, 160, 180, 200]).sort_index().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6bc4d8f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>city_pair</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>merged_POS</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Art</th>\n",
       "      <th>Diplomacy</th>\n",
       "      <th>Entertainment</th>\n",
       "      <th>Transportation</th>\n",
       "      <th>Education</th>\n",
       "      <th>idxmax</th>\n",
       "      <th>max</th>\n",
       "      <th>art</th>\n",
       "      <th>diplomacy</th>\n",
       "      <th>education</th>\n",
       "      <th>entertainment</th>\n",
       "      <th>sport</th>\n",
       "      <th>transportation</th>\n",
       "      <th>outcome</th>\n",
       "      <th>same_categorisation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>berlin_milan</td>\n",
       "      <td>after his tenure in academia, he continued to ...</td>\n",
       "      <td>[tenure, academia, month, year, travel, incide...</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.770121</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>0.224750</td>\n",
       "      <td>Diplomacy</td>\n",
       "      <td>0.770121</td>\n",
       "      <td>0.169194</td>\n",
       "      <td>1.928616</td>\n",
       "      <td>2.025882</td>\n",
       "      <td>0.309913</td>\n",
       "      <td>0.591317</td>\n",
       "      <td>1.040785</td>\n",
       "      <td>education</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>berlin_milan</td>\n",
       "      <td>there are plenty of air connections between ye...</td>\n",
       "      <td>[plenty, air, connection, city, connection, ci...</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.991741</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>0.991741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.510214</td>\n",
       "      <td>0.640919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.477014</td>\n",
       "      <td>4.445736</td>\n",
       "      <td>transportation</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>berlin_milan</td>\n",
       "      <td>since 2009, 'the brandery', an urban fashion s...</td>\n",
       "      <td>[fashion, year, language, monitor, ranking, wo...</td>\n",
       "      <td>0.383249</td>\n",
       "      <td>0.602904</td>\n",
       "      <td>0.003862</td>\n",
       "      <td>0.003379</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.003687</td>\n",
       "      <td>Art</td>\n",
       "      <td>0.602904</td>\n",
       "      <td>0.506511</td>\n",
       "      <td>0.468846</td>\n",
       "      <td>0.770001</td>\n",
       "      <td>0.309913</td>\n",
       "      <td>1.040841</td>\n",
       "      <td>0.087898</td>\n",
       "      <td>sport</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>berlin_milan</td>\n",
       "      <td>when considering the commuter belts or metropo...</td>\n",
       "      <td>[commuter, belt, area, datum, population, orde...</td>\n",
       "      <td>0.002721</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0.094386</td>\n",
       "      <td>0.005463</td>\n",
       "      <td>0.886130</td>\n",
       "      <td>0.005962</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>0.886130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.371927</td>\n",
       "      <td>0.119219</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.950457</td>\n",
       "      <td>transportation</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>berlin_milan</td>\n",
       "      <td>the eu contains about 40 urban areas with popu...</td>\n",
       "      <td>[area, population, population, area, megacity,...</td>\n",
       "      <td>0.002721</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0.094386</td>\n",
       "      <td>0.005463</td>\n",
       "      <td>0.886130</td>\n",
       "      <td>0.005962</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>0.886130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.915384</td>\n",
       "      <td>transportation</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310823</th>\n",
       "      <td>312682</td>\n",
       "      <td>warsaw_valencia</td>\n",
       "      <td>since 2010, edelmann has intensified his conce...</td>\n",
       "      <td>[concert, activity, guest, performance, recita...</td>\n",
       "      <td>0.001889</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>0.004335</td>\n",
       "      <td>0.982658</td>\n",
       "      <td>0.003276</td>\n",
       "      <td>0.004139</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>0.982658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099530</td>\n",
       "      <td>0.164835</td>\n",
       "      <td>3.578136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310824</th>\n",
       "      <td>312683</td>\n",
       "      <td>warsaw_valencia</td>\n",
       "      <td>born maria mokrzycka in lviv (now ukraine), sh...</td>\n",
       "      <td>[conservatory, debut, opera, opera, time, bari...</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>0.993306</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>0.993306</td>\n",
       "      <td>0.064806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.403735</td>\n",
       "      <td>6.039672</td>\n",
       "      <td>0.170935</td>\n",
       "      <td>0.479676</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310825</th>\n",
       "      <td>312684</td>\n",
       "      <td>warsaw_valencia</td>\n",
       "      <td>ayala was elected a fellow of the american aca...</td>\n",
       "      <td>[fellow, art, science, member, society, member...</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003862</td>\n",
       "      <td>0.003379</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.984857</td>\n",
       "      <td>Education</td>\n",
       "      <td>0.984857</td>\n",
       "      <td>1.120648</td>\n",
       "      <td>0.476482</td>\n",
       "      <td>4.250563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109702</td>\n",
       "      <td>education</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310826</th>\n",
       "      <td>312685</td>\n",
       "      <td>warsaw_valencia</td>\n",
       "      <td>o'conor was a co-founder of the dublin interna...</td>\n",
       "      <td>[co, founder, competition, director, chairman,...</td>\n",
       "      <td>0.001382</td>\n",
       "      <td>0.092213</td>\n",
       "      <td>0.003171</td>\n",
       "      <td>0.584548</td>\n",
       "      <td>0.002396</td>\n",
       "      <td>0.316290</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>0.584548</td>\n",
       "      <td>0.338868</td>\n",
       "      <td>0.490615</td>\n",
       "      <td>1.687384</td>\n",
       "      <td>0.408055</td>\n",
       "      <td>1.262192</td>\n",
       "      <td>0.568365</td>\n",
       "      <td>education</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310827</th>\n",
       "      <td>312686</td>\n",
       "      <td>warsaw_valencia</td>\n",
       "      <td>in october 2007, bakero joined ronald koeman's...</td>\n",
       "      <td>[teammate, staff, year, job, head, coach, team...</td>\n",
       "      <td>0.988496</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>0.002474</td>\n",
       "      <td>Sport</td>\n",
       "      <td>0.988496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.627616</td>\n",
       "      <td>1.456998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.003513</td>\n",
       "      <td>0.399042</td>\n",
       "      <td>sport</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>293400 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        paragraph_id        city_pair  \\\n",
       "0                  1     berlin_milan   \n",
       "2                  3     berlin_milan   \n",
       "3                  4     berlin_milan   \n",
       "4                  5     berlin_milan   \n",
       "5                  6     berlin_milan   \n",
       "...              ...              ...   \n",
       "310823        312682  warsaw_valencia   \n",
       "310824        312683  warsaw_valencia   \n",
       "310825        312684  warsaw_valencia   \n",
       "310826        312685  warsaw_valencia   \n",
       "310827        312686  warsaw_valencia   \n",
       "\n",
       "                                                paragraph  \\\n",
       "0       after his tenure in academia, he continued to ...   \n",
       "2       there are plenty of air connections between ye...   \n",
       "3       since 2009, 'the brandery', an urban fashion s...   \n",
       "4       when considering the commuter belts or metropo...   \n",
       "5       the eu contains about 40 urban areas with popu...   \n",
       "...                                                   ...   \n",
       "310823  since 2010, edelmann has intensified his conce...   \n",
       "310824  born maria mokrzycka in lviv (now ukraine), sh...   \n",
       "310825  ayala was elected a fellow of the american aca...   \n",
       "310826  o'conor was a co-founder of the dublin interna...   \n",
       "310827  in october 2007, bakero joined ronald koeman's...   \n",
       "\n",
       "                                               merged_POS     Sport       Art  \\\n",
       "0       [tenure, academia, month, year, travel, incide...  0.000765  0.001501   \n",
       "2       [plenty, air, connection, city, connection, ci...  0.000873  0.001713   \n",
       "3       [fashion, year, language, monitor, ranking, wo...  0.383249  0.602904   \n",
       "4       [commuter, belt, area, datum, population, orde...  0.002721  0.005337   \n",
       "5       [area, population, population, area, megacity,...  0.002721  0.005337   \n",
       "...                                                   ...       ...       ...   \n",
       "310823  [concert, activity, guest, performance, recita...  0.001889  0.003704   \n",
       "310824  [conservatory, debut, opera, opera, time, bari...  0.000729  0.001430   \n",
       "310825  [fellow, art, science, member, society, member...  0.001683  0.003300   \n",
       "310826  [co, founder, competition, director, chairman,...  0.001382  0.092213   \n",
       "310827  [teammate, staff, year, job, head, coach, team...  0.988496  0.002214   \n",
       "\n",
       "        Diplomacy  Entertainment  Transportation  Education          idxmax  \\\n",
       "0        0.770121       0.001536        0.001327   0.224750       Diplomacy   \n",
       "2        0.002005       0.001754        0.991741   0.001914  Transportation   \n",
       "3        0.003862       0.003379        0.002918   0.003687             Art   \n",
       "4        0.094386       0.005463        0.886130   0.005962  Transportation   \n",
       "5        0.094386       0.005463        0.886130   0.005962  Transportation   \n",
       "...           ...            ...             ...        ...             ...   \n",
       "310823   0.004335       0.982658        0.003276   0.004139   Entertainment   \n",
       "310824   0.001673       0.993306        0.001264   0.001597   Entertainment   \n",
       "310825   0.003862       0.003379        0.002918   0.984857       Education   \n",
       "310826   0.003171       0.584548        0.002396   0.316290   Entertainment   \n",
       "310827   0.002591       0.002267        0.001958   0.002474           Sport   \n",
       "\n",
       "             max       art  diplomacy  education  entertainment     sport  \\\n",
       "0       0.770121  0.169194   1.928616   2.025882       0.309913  0.591317   \n",
       "2       0.991741  0.000000   0.510214   0.640919       0.000000  0.477014   \n",
       "3       0.602904  0.506511   0.468846   0.770001       0.309913  1.040841   \n",
       "4       0.886130  0.000000   0.000000   0.371927       0.119219  0.000000   \n",
       "5       0.886130  0.000000   0.000000   0.449584       0.000000  0.000000   \n",
       "...          ...       ...        ...        ...            ...       ...   \n",
       "310823  0.982658  0.000000   0.099530   0.164835       3.578136  0.000000   \n",
       "310824  0.993306  0.064806   0.000000   2.403735       6.039672  0.170935   \n",
       "310825  0.984857  1.120648   0.476482   4.250563       0.000000  0.000000   \n",
       "310826  0.584548  0.338868   0.490615   1.687384       0.408055  1.262192   \n",
       "310827  0.988496  0.000000   0.627616   1.456998       0.000000  3.003513   \n",
       "\n",
       "        transportation         outcome  same_categorisation  \n",
       "0             1.040785       education                False  \n",
       "2             4.445736  transportation                 True  \n",
       "3             0.087898           sport                False  \n",
       "4             0.950457  transportation                 True  \n",
       "5             0.915384  transportation                 True  \n",
       "...                ...             ...                  ...  \n",
       "310823        0.000000   entertainment                 True  \n",
       "310824        0.479676   entertainment                 True  \n",
       "310825        0.109702       education                 True  \n",
       "310826        0.568365       education                False  \n",
       "310827        0.399042           sport                 True  \n",
       "\n",
       "[293400 rows x 20 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['max'] > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "39db033d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195836"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['max'] > 0.5) & (df['merged_POS'].str.len() > 20)]['same_categorisation'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f764e55",
   "metadata": {},
   "source": [
    "### Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e8ab1be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idxmax          same_categorisation\n",
       "Art             True                   1212\n",
       "                False                   971\n",
       "Diplomacy       True                   3283\n",
       "                False                  1456\n",
       "Education       True                   1042\n",
       "                False                    21\n",
       "Entertainment   True                   1765\n",
       "                False                    43\n",
       "Sport           True                   2084\n",
       "                False                     1\n",
       "Transportation  True                   1196\n",
       "                False                   362\n",
       "Name: same_categorisation, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  & len(df['merged_POS'].str) > 20\n",
    "df[(df['max'] > 0.5) & (df['merged_POS'].str.len() > 80)].groupby('idxmax')['same_categorisation'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376959da",
   "metadata": {},
   "source": [
    "### Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a4b0b67a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idxmax          same_categorisation\n",
       "Art             True                   0.555199\n",
       "                False                  0.444801\n",
       "Diplomacy       True                   0.692762\n",
       "                False                  0.307238\n",
       "Education       True                   0.980245\n",
       "                False                  0.019755\n",
       "Entertainment   True                   0.976217\n",
       "                False                  0.023783\n",
       "Sport           True                   0.999520\n",
       "                False                  0.000480\n",
       "Transportation  True                   0.767651\n",
       "                False                  0.232349\n",
       "Name: same_categorisation, dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['max'] > 0.5) & (df['merged_POS'].str.len() > 80)].groupby('idxmax')['same_categorisation'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a29d22d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education         0.616014\n",
       "entertainment     0.144989\n",
       "sport             0.093962\n",
       "transportation    0.081474\n",
       "diplomacy         0.063561\n",
       "Name: outcome, dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['idxmax'] == 'Art') & (df['outcome'] != 'art')]['outcome'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1e706200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education         0.643063\n",
       "transportation    0.139675\n",
       "sport             0.105413\n",
       "entertainment     0.080637\n",
       "art               0.031213\n",
       "Name: outcome, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['idxmax'] == 'Diplomacy') & (df['outcome'] != 'diplomacy')]['outcome'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9c98cb4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education        0.580069\n",
       "diplomacy        0.172595\n",
       "sport            0.131271\n",
       "entertainment    0.070876\n",
       "art              0.045189\n",
       "Name: outcome, dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['idxmax'] == 'Transportation') & (df['outcome'] != 'transportation')]['outcome'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "7e848b5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'outcome'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\Personal Files [Local]\\Applied Data Science\\Thesis - CITYNET\\venv_citynet3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\Personal Files [Local]\\Applied Data Science\\Thesis - CITYNET\\venv_citynet3\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\Personal Files [Local]\\Applied Data Science\\Thesis - CITYNET\\venv_citynet3\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'outcome'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [265]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutcome\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mnotna()]\n",
      "File \u001b[1;32m~\\Personal Files [Local]\\Applied Data Science\\Thesis - CITYNET\\venv_citynet3\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\Personal Files [Local]\\Applied Data Science\\Thesis - CITYNET\\venv_citynet3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'outcome'"
     ]
    }
   ],
   "source": [
    "df3[df3['outcome'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0796bdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorize_text(words=lemmatised_words, number_of_keywords=1, bottom_threshold=0.1, verbose1=False, verbose2=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf54d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorize_group_of_texts \n",
    "\n",
    "# def categorize_group_of_texts(lemmatized_wordlists, keywords, embeddings_dict, number_of_keywords=1, bottom_threshold=0.1, verbose1=False, verbose2=False):\n",
    "#     categories = {}\n",
    "#     for index, lemmatized_wordlist in tqdm(enumerate(lemmatized_wordlists), total=len(lemmatized_wordlists)):\n",
    "#         prediction_dict = categorize_text(lemmatized_wordlist=lemmatized_wordlist, keywords=keywords, embeddings_dict=embeddings_dict, number_of_keywords=number_of_keywords, bottom_threshold=bottom_threshold, verbose1=verbose1, verbose2=verbose2)\n",
    "#         try:\n",
    "#             categories[prediction_dict['prediction']] +=1\n",
    "#         except:\n",
    "#             categories[prediction_dict['prediction']] = 1\n",
    "    \n",
    "#     return categories"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
