{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c0d8fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diede\\Personal Files [Local]\\Applied Data Science\\Thesis - CITYNET\\venv_citynet3\\lib\\site-packages\\past\\builtins\\misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n"
     ]
    }
   ],
   "source": [
    "from preprocessing_functions import *\n",
    "from topic_modeling_functions import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f59bdb2",
   "metadata": {},
   "source": [
    "### Import Lemmatised Paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a56d516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a075a6c74c3a47c98127738d446a480a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BATCHES: ['5']:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "City Pair:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "INPUT_DIR = \"../../../../../data/clean/city_pair_paragraphs3/\"\n",
    "BATCHES = [5]\n",
    "POS = [\"NOUN\", \"VERB\", \"ADJ\"]\n",
    "ONLY_ENGLISH_WORDS = True\n",
    "sort_by_paragraphs_count = True\n",
    "merged_POS = True\n",
    "\n",
    "data_list = import_lemmatised_paragraphs(INPUT_DIR, POS, BATCHES, ONLY_ENGLISH_WORDS=ONLY_ENGLISH_WORDS, merged_POS=merged_POS, sort_by_paragraphs=sort_by_paragraphs_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d7d5f2",
   "metadata": {},
   "source": [
    "### Create Single Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c660bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_pair</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>merged_POS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paragraph_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>berlin_milan</td>\n",
       "      <td>after his tenure in academia, he continued to ...</td>\n",
       "      <td>[tenure, academia, month, year, travel, incide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>berlin_milan</td>\n",
       "      <td>one of the astronomers selected for the search...</td>\n",
       "      <td>[astronomer, search, priest, invitation, group...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>berlin_milan</td>\n",
       "      <td>there are plenty of air connections between ye...</td>\n",
       "      <td>[plenty, air, connection, city, connection, ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>berlin_milan</td>\n",
       "      <td>since 2009, 'the brandery', an urban fashion s...</td>\n",
       "      <td>[fashion, year, language, monitor, ranking, wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>berlin_milan</td>\n",
       "      <td>when considering the commuter belts or metropo...</td>\n",
       "      <td>[commuter, belt, area, datum, population, orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50891</th>\n",
       "      <td>paris_milan</td>\n",
       "      <td>the impressions that he had made by his speech...</td>\n",
       "      <td>[impression, speech, debate, invitation, repre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50892</th>\n",
       "      <td>paris_milan</td>\n",
       "      <td>a journey to paris in 1790 provided him furthe...</td>\n",
       "      <td>[journey, acquaintance, idea, year, city, gran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50893</th>\n",
       "      <td>paris_milan</td>\n",
       "      <td>the 1993–94 uefa champions league was the 39th...</td>\n",
       "      <td>[season, club, football, tournament, season, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50894</th>\n",
       "      <td>paris_milan</td>\n",
       "      <td>kaya has been modeling since the age of 14. sh...</td>\n",
       "      <td>[age, street, career, fashion, world, catalogu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50895</th>\n",
       "      <td>paris_milan</td>\n",
       "      <td>he was born as donald marc blumberg in new hav...</td>\n",
       "      <td>[art, drama, costume, clothing, designer, desi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50496 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 city_pair                                          paragraph  \\\n",
       "paragraph_id                                                                    \n",
       "1             berlin_milan  after his tenure in academia, he continued to ...   \n",
       "2             berlin_milan  one of the astronomers selected for the search...   \n",
       "3             berlin_milan  there are plenty of air connections between ye...   \n",
       "4             berlin_milan  since 2009, 'the brandery', an urban fashion s...   \n",
       "5             berlin_milan  when considering the commuter belts or metropo...   \n",
       "...                    ...                                                ...   \n",
       "50891          paris_milan  the impressions that he had made by his speech...   \n",
       "50892          paris_milan  a journey to paris in 1790 provided him furthe...   \n",
       "50893          paris_milan  the 1993–94 uefa champions league was the 39th...   \n",
       "50894          paris_milan  kaya has been modeling since the age of 14. sh...   \n",
       "50895          paris_milan  he was born as donald marc blumberg in new hav...   \n",
       "\n",
       "                                                     merged_POS  \n",
       "paragraph_id                                                     \n",
       "1             [tenure, academia, month, year, travel, incide...  \n",
       "2             [astronomer, search, priest, invitation, group...  \n",
       "3             [plenty, air, connection, city, connection, ci...  \n",
       "4             [fashion, year, language, monitor, ranking, wo...  \n",
       "5             [commuter, belt, area, datum, population, orde...  \n",
       "...                                                         ...  \n",
       "50891         [impression, speech, debate, invitation, repre...  \n",
       "50892         [journey, acquaintance, idea, year, city, gran...  \n",
       "50893         [season, club, football, tournament, season, l...  \n",
       "50894         [age, street, career, fashion, world, catalogu...  \n",
       "50895         [art, drama, costume, clothing, designer, desi...  \n",
       "\n",
       "[50496 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [citypair['lemmatized_paragraphs'] for citypair in data_list]\n",
    "citypairs = [citypair['city_pair'] for citypair in data_list]\n",
    "\n",
    "result = pd.concat(frames, keys=citypairs)\n",
    "result.set_index('paragraph_id', inplace=True)\n",
    "result.sort_index(inplace=True)\n",
    "result\n",
    "# result.loc[\"paris_london\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d937d97",
   "metadata": {},
   "source": [
    "### Training Multiple LDA Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e38dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC_SELECTION = range(2,21,1)\n",
    "list(TOPIC_SELECTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d4e2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.exists(\"../../../../../data/clean/lda_models/50k_paragraphs/0.05min_0.9max/lda_model_2topics_0.05min_0.9max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7033aa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "TOPIC_SELECTION = range(2,21, 1)\n",
    "paragraphs = result.merged_POS\n",
    "MIN_DF = 0.1\n",
    "MAX_DF = 0.8\n",
    "\n",
    "# Vectorization\n",
    "dictionary, corpus = vectorize(paragraphs, MIN_DF=MIN_DF, MAX_DF=MAX_DF)\n",
    "\n",
    "models = compare_lda_models(OUTPUT_DIR='../../../../../data/clean/lda_models/50k_paragraphs/', TOPIC_SELECTION=TOPIC_SELECTION,\n",
    "                LEMMATIZED_TEXT=paragraphs, DICTIONARY=dictionary, CORPUS=corpus, MIN_DF=MIN_DF, MAX_DF=MAX_DF, N_ITERATIONS=1000,\n",
    "                PATH_TO_MALLET=r'C:/mallet/bin/mallet.bat', GET_COHERENCE_SCORE=True, COHERENCE='c_v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1324bb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = '../../../../../data/clean/lda_models/50k_paragraphs/0.05min_0.9max/'\n",
    "n = f\"lda_model_2topics_0.05min_0.9max\"\n",
    "#os.path.join(directory, f\"{NAME}_visualisation.html\")\n",
    "print(os.path.exists(os.path.join(p, n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c1ab4c",
   "metadata": {},
   "source": [
    "### Load Multiple LDA Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb045bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "loaded_models = load_lda_models(INPUT_DIR='../../../../../data/clean/lda_models/50k_paragraphs/', LOAD_VIS=True,\n",
    "                                LOAD_DICT=True, LOAD_COHERENCE_SCORE=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2620a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in loaded_models:\n",
    "    if len(model['model'].show_topics(50)) != 10:\n",
    "        print(len(model['model'].show_topics(50)), model['coherence_score'])\n",
    "        print()\n",
    "#     try:\n",
    "#         print(len(model['model'].show_topics(50)))\n",
    "#     except:\n",
    "#         print('check')\n",
    "loaded_models[13]['visualisation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5021e698",
   "metadata": {},
   "outputs": [],
   "source": [
    "result\n",
    "# len(result.paragraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75570f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(new_df[new_df['paragraph_id'] == 23065]['merged_POS'])[0]\n",
    "#[data_list[1]['lemmatized_paragraphs']['paragraph_id'] == 21065]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15877b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_models[8]['visualisation']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05cd3bb",
   "metadata": {},
   "source": [
    "### Load Chosen Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fa5595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "f = '../../../../../data/clean/lda_models/50k_paragraphs/0_05MIN_0_9MAX/lda_model_8topics_0_05min_0_9max/lda_model_8topics_0_05min_0_9max_texts.pickle'\n",
    "\n",
    "with open(f, 'rb') as fp:\n",
    "                    a = pickle.load(fp)\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "681705cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:random_state not set so using default value\n",
      "WARNING:root:failed to load state from C:\\Users\\diede\\Personal Files [Local]\\Applied Data Science\\Thesis - CITYNET\\data\\clean\\lda_models\\50k_paragraphs\\0_05MIN_0_9MAX\\lda_model_8topics_0_05min_0_9max\\lda_8topics_0_05min_0_9max_model_model.model.state: [Errno 2] No such file or directory: 'C:\\\\Users\\\\diede\\\\Personal Files [Local]\\\\Applied Data Science\\\\Thesis - CITYNET\\\\data\\\\clean\\\\lda_models\\\\50k_paragraphs\\\\0_05MIN_0_9MAX\\\\lda_model_8topics_0_05min_0_9max\\\\lda_8topics_0_05min_0_9max_model_model.model.state'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gensim.models.wrappers.ldamallet.LdaMallet object at 0x000001B8A5404B20>\n"
     ]
    }
   ],
   "source": [
    "P = \"../../../../../data/clean/lda_models/50k_paragraphs/0_05MIN_0_9MAX/lda_model_8topics_0_05min_0_9max/\"\n",
    "# P = \"../../../../../data/clean/lda_models/50k_paragraphs/lda_model_8topics_0_1min_0_8max\"\n",
    "P = os.path.abspath(P)\n",
    "model = load_lda_model(P, LOAD_VIS=True, LOAD_DICT=True, LOAD_TEXTS=True, LOAD_COHERENCE_SCORE=True)\n",
    "\n",
    "# for file in os.listdir(P):\n",
    "#     #model = gensim.models.LdaModel.load(P)\n",
    "    \n",
    "    \n",
    "#     if 'dictionary' in file:\n",
    "#         print(os.path.exists(os.path.abspath(os.path.join(P, file))))\n",
    "#         # print(os.path.exists())\n",
    "\n",
    "\n",
    "# os.path.exists(os.path.join(P, os.listdir(P)[-1]))\n",
    "# os.path.exists('../../../../../data/clean/lda_models/50k_paragraphs/0_05MIN_0_9MAX/lda_model_8topics_0.05min_0.9max/lda_model_8topics_0.05min_0.9max_dictionary.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bb6663f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model', 'coherence_score', 'visualisation', 'lemmatised_documents', 'dictionary', 'texts'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d952184f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "old_file_name = \"/home/career_karma/raw_data.csv\"\n",
    "new_file_name = \"/home/career_karma/old_data.csv\"\n",
    "\n",
    "os.rename(old_file_name, new_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bb138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../../../../../data/clean/lda_models/50k_paragraphs/\"\n",
    "#N_TOPICS = 8\n",
    "\n",
    "for folder in os.listdir(model_path):\n",
    "    path2 = os.path.join(model_path, folder)\n",
    "    \n",
    "    for folder2 in os.listdir(path2):\n",
    "        old_path = os.path.join(path2, folder2)\n",
    "        old_abs_path = os.path.abspath(old_path)\n",
    "        new_path = old_abs_path.replace(\"0.05min\", \"0_05min\").replace(\"0.9max\", \"0_9max\")# .replace('.dict', '_dict').replace('.model', '_model')\n",
    "        new_abs_path = os.path.abspath(new_path)\n",
    "        \n",
    "        os.rename(old_abs_path, new_abs_path)\n",
    "        \n",
    "        # print(os.path.exists())\n",
    "        # new_path = os.path.join(path2, p)\n",
    "        # print(old_path)\n",
    "        \n",
    "#         try:\n",
    "#             \n",
    "#             print(new_path)\n",
    "#             print('check')\n",
    "#         except:\n",
    "#             print(old_path)\n",
    "#             print(new_path)\n",
    "#             print()\n",
    "        \n",
    "            # print(old_path)\n",
    "        #print(folder2)\n",
    "        #old_path = os.path.join(path2, folder2)\n",
    "        #print(os.path.exists(old_path))\n",
    "   # p = folder.replace(\"0.1min\", \"0_1min\").replace(\"0_max\", \"0_8max\")\n",
    "   #  os.rename(path2, os.path.join(model_path, p))\n",
    "        #new_path = os.path.join(path2, p)\n",
    "        #os.rename(old_path, new_path)\n",
    "        # path3 = os.path.join(path2, folder2)\n",
    "        # print(os.path.exists(path3))\n",
    "#         for file in os.listdir(path3):\n",
    "#             print(file)\n",
    "        # pass\n",
    "        # p = os.path.join(path2, folder2).strip()\n",
    "        # print(p[:10])\n",
    "        #\n",
    "        #print(p)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# if os.path.exists(model_path):\n",
    "#     print('ee')\n",
    "\n",
    "# for f in os.listdir(model_path):\n",
    "#     if '0.05min' and '0.9max' in f:\n",
    "#         print(f)\n",
    "        \n",
    "    # print(f)\n",
    "    #path = model_path + '/' + \"lda_8topics_0_05min_0_9max_model.model\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceab860",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bca5990",
   "metadata": {},
   "source": [
    "### Word Topic Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2347a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N_TOPICS):\n",
    "    topic_words = model['model'].show_topic(i, topn=MAX_WORDS)\n",
    "    print(i+1, [(x[0], round(x[1], 3)) for x in topic_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43546bc0",
   "metadata": {},
   "source": [
    "### Document Topic Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f6c666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "transformed_docs = lda_model.load_document_topics()\n",
    "topic_distributions = pd.DataFrame([[x[1] for x in doc] for doc in transformed_docs], \n",
    "             columns=['topic_{}'.format(i+1) for i in range(N_TOPICS)])\n",
    "topic_distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5e9ca3",
   "metadata": {},
   "source": [
    "### Topic Coverage Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e26d9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = topic_distributions.mean().sort_values(ascending=False)\n",
    "sorted_distribution = distribution.sort_index()\n",
    "distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c14de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "langs = sorted_distribution.index\n",
    "students = list(sorted_distribution)\n",
    "ax.bar(langs,students)\n",
    "average_topic_coverage = sum(sorted_distribution)/len(sorted_distribution)\n",
    "\n",
    "plt.axhline(average_topic_coverage, color='grey', ls='-', label='average topic coverage')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
