{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "411897a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d636875",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diedfunctions import * # 'Kernel restart & clear output' to load new functions\n",
    "from collections import Counter\n",
    "from wordfreq import word_frequency \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4073a52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_pair = 'paris_madrid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aa4f748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1293472"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textfile = f'../../../../enwiki_city_pairs/{city_pair}.txt'\n",
    "\n",
    "with open(textfile, 'r', encoding='utf-16') as f:\n",
    "    city_pair_text_list = [x.strip().lower() for x in f.read().split('\\n') if len(x) and 'title=' not in x]\n",
    "\n",
    "city_pair_text = ' '.join(city_pair_text_list)\n",
    "len(city_pair_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "129d3bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(city_pair_text_list)-1)//5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a21d0645",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = (len(city_pair_text_list)-1)//5+1\n",
    "chunked_text =[' '.join(city_pair_text_list[offs:offs+chunk_size]) for offs in range(0, len(city_pair_text_list), chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa8a21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_text[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5269429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 2s\n",
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# To big to work...\n",
    "output = lemmatize(city_pair_text, nlp_max_length=1500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0b980d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ner', 'parser']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import re\n",
    "\n",
    "nlp.max_length = 1500000\n",
    "nlp.disable_pipes('ner', 'parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b65a7290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 23.9 s\n",
      "Wall time: 26.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "POSfilter=[\"PROPN\", \"NOUN\", \"ADJ\", \"VERB\", \"ADV\", \"NUM\"]\n",
    "POSfilter=[\"NOUN\"]\n",
    "processed_text = nlp(city_pair_text.lower())\n",
    "lemmatized_text = [word.lemma_.lower() for word in processed_text if word.pos_ in POSfilter and not word.is_punct and not word.is_stop] # \n",
    "regexed_text = [re.sub(r'\\W+', '', word) for word in lemmatized_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8abdfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "special arrangements were made to allow the public to see many royal or private collections placed in galleries, as with the orleans collection mostly housed in a wing of the palais royal in paris, which could be visited for most of the 18th century. in italy the art tourism of the grand tour became a major industry from the renaissance onwards, and governments and cities made efforts to make their key works accessible. the british royal collection remains distinct, but large donations such as the old royal library were made from it to the\n",
      "\n",
      "['arrangement', 'public', 'collection', 'gallery', 'collection', 'wing', 'royal', 'century', 'art', 'tourism', 'tour', 'industry', 'renaissance', 'government', 'city', 'effort', 'work', 'royal', 'collection', 'donation', 'library', 'florence', 'gallery', 'function', 'building', 'servant', 'office', 'time', 'building', 'prado', 'revolution', 'display', 'part', 'art', 'collection', 'gallery', 'public', 'vienna', 'munich', 'capital', 'opening', 'revolution', 'museum', 'royal', 'collection', 'stage', 'development', 'access', 'art', 'ownership', 'state', 'continuation', 'trend', 'city', 'coast', 'capital', 'city', 'community', 'municipality', 'population', 'city', 'limit', 'area', 'neighbouring', 'municipality', 'province', 'home', 'people', 'area', 'metropolis', 'coast', 'mouth', 'river', 'west', 'mountain', 'range', 'peak', 'renfe', 'speed', 'rail', 'system', 'speed', 'form', 'speed', 'rail', 'line', 'renfe', 'speed', 'rail', 'barcelona', 'marseille', 'toulouse', 'speed', 'rail', 'line', 'line', 'sant', 'station', 'route', 'route']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8900"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(processed_text[:100])\n",
    "print()\n",
    "print(regexed_text[:100])\n",
    "len(Counter(regexed_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b12114e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "special arrangements were made to allow the public to see many royal or private collections placed in galleries, as with the orleans collection mostly housed in a wing of the palais royal in paris, which could be visited for most of the 18th century. in italy the art tourism of the grand tour became a major industry from the renaissance onwards, and governments and cities made efforts to make their key works accessible. the british royal collection remains distinct, but large donations such as the old royal library were made from it to the\n",
      "\n",
      "['special', 'arrangement', 'allow', 'public', 'royal', 'private', 'collection', 'place', 'gallery', 'orleans', 'collection', 'house', 'wing', 'palais', 'royal', 'paris', 'visit', '18th', 'century', 'italy', 'art', 'tourism', 'grand', 'tour', 'major', 'industry', 'renaissance', 'onwards', 'government', 'city', 'effort', 'key', 'work', 'accessible', 'british', 'royal', 'collection', 'remain', 'distinct', 'large', 'donation', 'old', 'royal', 'library', 'british', 'museum', 'establish', '1753', 'uffizi', 'florence', 'open', 'entirely', 'gallery', '1765', 'function', 'gradually', 'take', 'building', 'original', 'civil', 'servant', 'office', 'long', 'time', 'building', 'occupy', 'prado', 'madrid', 'build', 'french', 'revolution', 'public', 'display', 'part', 'royal', 'art', 'collection', 'similar', 'royal', 'gallery', 'open', 'public', 'exist', 'vienna', 'munich', 'capital', 'opening', 'musée', 'du', 'louvre', 'french', 'revolution', '1793', 'public', 'museum', 'french', 'royal', 'collection', 'certainly', 'mark']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19690"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(processed_text[:100])\n",
    "print()\n",
    "print(regexed_text[:100])\n",
    "len(Counter(regexed_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5b258ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "special arrangements were made to allow the public to see many royal or private collections placed in galleries, as with the orleans collection mostly housed in a wing of the palais royal in paris, which could be visited for most of the 18th century. in italy the art tourism of the grand tour became a major industry from the renaissance onwards, and governments and cities made efforts to make their key works accessible. the british royal collection remains distinct, but large donations such as the old royal library were made from it to the\n",
      "\n",
      "['special', 'arrangement', 'allow', 'public', 'royal', 'private', 'collection', 'place', 'gallery', 'orleans', 'collection', 'house', 'wing', 'palais', 'royal', 'paris', 'visit', '18th', 'century', 'italy', 'art', 'tourism', 'grand', 'tour', 'major', 'industry', 'renaissance', 'onwards', 'government', 'city', 'effort', 'key', 'work', 'accessible', 'british', 'royal', 'collection', 'remain', 'distinct', 'large', 'donation', 'old', 'royal', 'library', 'british', 'museum', 'establish', 'uffizi', 'florence', 'open', 'entirely', 'gallery', 'function', 'gradually', 'take', 'building', 'original', 'civil', 'servant', 'office', 'long', 'time', 'building', 'occupy', 'prado', 'madrid', 'build', 'french', 'revolution', 'public', 'display', 'part', 'royal', 'art', 'collection', 'similar', 'royal', 'gallery', 'open', 'public', 'exist', 'vienna', 'munich', 'capital', 'opening', 'musée', 'du', 'louvre', 'french', 'revolution', 'public', 'museum', 'french', 'royal', 'collection', 'certainly', 'mark', 'important', 'stage', 'development']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18690"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(processed_text[:100])\n",
    "print()\n",
    "print(regexed_text[:100])\n",
    "len(Counter(regexed_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980c93a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "POSfilter=[\"PROPN\", \"NOUN\", \"ADJ\", \"VERB\", \"ADV\"]\n",
    "processed_text2 = nlp(city_pair_text.lower())\n",
    "# lemmatized_text = [word.lemma_.lower() for word in processed_text if word.pos_ in POSfilter and not word.is_punct and not word.is_stop]\n",
    "regexed_text = [re.sub(r'\\W+', '', word.lemma_.lower()) for word in processed_text2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c457ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_pipe(doc):\n",
    "    lemma_list = [tok.lemma_.lower() for tok in doc\n",
    "                  if tok.pos_ in POSfilter and not tok.is_punct and not tok.is_stop] \n",
    "    return lemma_list\n",
    "\n",
    "def preprocess_pipe(texts):\n",
    "    preproc_pipe = []\n",
    "    for doc in nlp.pipe(texts, batch_size=20):\n",
    "        preproc_pipe.append(lemmatize_pipe(doc))\n",
    "    return preproc_pipe\n",
    "\n",
    "\n",
    "\n",
    "#     lemma_list = [tok.lemma_.lower() for tok in doc\n",
    "#                   if tok.is_alpha and tok.text.lower() not in stopwords] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c184bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "29f251dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "236a9f42a5954ad7a4e1c3374d99b9a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.58 s\n",
      "Wall time: 18.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "processed_text = [text for text in tqdm(nlp.pipe(chunked_text, n_process=2, disable=[\"ner\", \"parser\"]), total=len(chunked_text))]\n",
    "lemmatized_text = [[word.lemma_.lower() for word in text if word.pos_ in POSfilter and not word.is_punct and not word.is_stop] for text in processed_text]\n",
    "regexed_text = [[re.sub(r'\\W+', '', word) for word in text] for text in lemmatized_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a78904a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8900"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Counter([item for sublist in regexed_text for item in sublist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d3ecc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "output2 = preprocess_pipe(chunked_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d88c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def chunker(iterable, total_length, chunksize):\n",
    "    return (iterable[pos: pos + chunksize] for pos in range(0, total_length, chunksize))\n",
    "\n",
    "def flatten(list_of_lists):\n",
    "    \"Flatten a list of lists to a combined list\"\n",
    "    return [item for sublist in list_of_lists for item in sublist]\n",
    "\n",
    "def process_chunk(texts):\n",
    "    preproc_pipe = []\n",
    "    for doc in nlp.pipe(texts, batch_size=20):\n",
    "        preproc_pipe.append(lemmatize_pipe(doc))\n",
    "    return preproc_pipe\n",
    "\n",
    "def preprocess_parallel(texts, chunksize=1):\n",
    "    executor = Parallel(n_jobs=7, backend='multiprocessing', prefer=\"processes\")\n",
    "    do = delayed(process_chunk)\n",
    "    tasks = (do(chunk) for chunk in chunker(texts, len(texts), chunksize=chunksize))\n",
    "    result = executor(tasks)\n",
    "    return flatten(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2e8563",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32744321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "from multiprocessing_died import preprocess_parallel\n",
    "#!pip install multiprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e882814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "CPU times: total: 141 ms\n",
      "Wall time: 36.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "output3 = preprocess_parallel(chunked_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9caa07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3697b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8ed565",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_list = [[x[0], x[1]] for x in (Counter(output).most_common(100))]\n",
    "\n",
    "for index, content in enumerate(frequency_list):\n",
    "    frequency_list[index].append(word_frequency(content[0], 'en'))\n",
    "    #print('{0: <20} {1: <5} {2: <3}'.format(word,freq, word_frequency(word, 'en')))\n",
    "    #print(word, freq, word_frequency(word, 'en'))\n",
    "\n",
    "frequency_list\n",
    "\n",
    "sorted_relevance = sorted(frequency_list, key=lambda x: x[2], reverse=True)\n",
    "sorted(sorted_relevance[-25:], key=lambda x: x[1], reverse=True)[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f03831",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
