{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e2d3644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lbl2vec\n",
    "from lbl2vec import Lbl2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57044dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b5bfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wheel\n",
    "# !python -m pip install -U pip setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76c3cc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pip==22.1.2\n",
    "# !pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4727b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54d0d525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fasttext.util\n",
    "# fasttext.util.download_model('en', if_exists='ignore')  # English\n",
    "# ft = fasttext.load_model('cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f876959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gensim.models as g\n",
    "\n",
    "# # model=\"../../../../enwiki_dbow/doc2vec.bin\"  #point to downloaded pre-trained doc2vec model\n",
    "# model='../../../../cc.en.300.bin'\n",
    "# #load model\n",
    "# m = g.Doc2Vec.load(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8a6263",
   "metadata": {},
   "source": [
    "# Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db41cdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict = ['war', 'fight', 'death', 'hostility', 'bomb', 'battle', 'nazi', 'army']\n",
    "politics = ['politics', 'debate', 'election', 'government', 'democracy']\n",
    "fashion = ['fashion', 'model', 'magazine', 'walk', 'glamour', 'outfit']\n",
    "culture = ['culture', 'opera', \"festival\", 'collection', 'exhibition', 'art', 'museum']\n",
    "sports = ['sport', 'medal', 'game', 'championship', 'club', 'score', 'play']\n",
    "education = ['education', 'professor', 'study', 'research', 'university']\n",
    "# football = []\n",
    "# other\n",
    "\n",
    "descriptive_keywords = [conflict, politics, fashion, culture, sports, education]\n",
    "# How to avoid words with high tf?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc7ac8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['war', 'fight', 'death', 'hostility', 'bomb', 'battle', 'nazi', 'army'],\n",
       " ['politics', 'debate', 'election', 'government', 'democracy'],\n",
       " ['fashion', 'model', 'magazine', 'walk', 'glamour', 'outfit'],\n",
       " ['culture', 'opera', 'festival', 'collection', 'exhibition', 'art', 'museum'],\n",
       " ['sport', 'medal', 'game', 'championship', 'club', 'score', 'play'],\n",
       " ['education', 'professor', 'study', 'research', 'university']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptive_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d5c0047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2977e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORDLIST_LOCATION = '../../../../data/enwiki_city_pairs_lemmatised/NOUN_SPACY_LARGE_REAL_WORDS/biggest_cities_5'\n",
    "wordlists = []\n",
    "city_pairs = []\n",
    "\n",
    "for root, dirs, files in os.walk(WORDLIST_LOCATION, topdown=True):\n",
    "    for name in files:\n",
    "        file_path = os.path.join(root, name)\n",
    "        \n",
    "        with open(file_path, 'rb') as fp:\n",
    "            wordlists.append(pickle.load(fp))\n",
    "            city_pairs.append(name.split('__')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e11c537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "427850 paris_london\n",
      "152094 london_berlin\n",
      "151175 paris_berlin\n",
      "61672 paris_milan\n",
      "60544 paris_madrid\n",
      "46708 london_milan\n",
      "45255 london_madrid\n",
      "22840 madrid_milan\n",
      "19438 madrid_berlin\n",
      "17341 berlin_milan\n"
     ]
    }
   ],
   "source": [
    "# Sort by number of words\n",
    "\n",
    "data = list(zip(wordlists, city_pairs))\n",
    "sorted_data = sorted(data, key=lambda x: len(x[0]), reverse=True)\n",
    "\n",
    "for x in sorted_data[:20]:\n",
    "    print(len(x[0]), x[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7dc2fe63",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sorted_data[0][0]), sorted_data[0][1]\n",
    "c = Counter(sorted_data[0][0])\n",
    "most_common = c.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090b97b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "825746cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import spatial\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3739b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_LOCATION = '../../../../glove.42B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bd79ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "658a7c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81e525decb1540248c23d1db0005ca0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1917495 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 6s\n",
      "Wall time: 3min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time # ~3 minutes to load\n",
    "\n",
    "num_lines = sum(1 for line in open(GLOVE_LOCATION,'r', encoding=\"utf-8\"))\n",
    "\n",
    "with open(GLOVE_LOCATION, 'r', encoding=\"utf-8\") as f:\n",
    "     for line in tqdm(f, total=num_lines):\n",
    "        values = line.split()\n",
    "        token = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[token] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d26083c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['war', 'fight', 'death', 'hostility', 'bomb', 'battle', 'nazi', 'army'],\n",
       " ['politics', 'debate', 'election', 'government', 'democracy'],\n",
       " ['fashion', 'model', 'magazine', 'walk', 'glamour', 'outfit'],\n",
       " ['culture', 'opera', 'festival', 'collection', 'exhibition', 'art', 'museum'],\n",
       " ['sport', 'medal', 'game', 'championship', 'club', 'score', 'play'],\n",
       " ['education', 'professor', 'study', 'research', 'university']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptive_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db0e597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distance between two words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf8abb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3141452968120575\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "word_1 = embeddings_dict['fashion']\n",
    "word_2 = embeddings_dict['war']\n",
    "print(1 - cosine(word_1, word_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "82d212c1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['art', 'year', 'work', 'time', 'city', 'exhibition', 'world', 'opera', 'school', 'music', 'company', 'artist', 'gallery', 'film', 'member', 'museum', 'festival', 'war', 'society', 'painting', 'family', 'collection', 'tour', 'service', 'life', 'book', 'study', 'performance', 'concert', 'group', 'fashion', 'career', 'role', 'day', 'office', 'father', 'theatre', 'house', 'woman', 'government', 'country', 'century', 'son', 'place', 'production', 'studio', 'orchestra', 'director', 'college', 'number', 'man', 'album', 'history', 'event', 'design', 'child', 'week', 'month', 'death', 'ballet', 'age', 'end', 'friend', 'university', 'club', 'portrait', 'business', 'series', 'song', 'period', 'professor', 'stage', 'wife', 'painter', 'magazine', 'band', 'state', 'people', 'academy', 'summer', 'symphony', 'daughter', 'student', 'success', 'award', 'title', 'home', 'amp', 'mother', 'king', 'project', 'brother', 'street', 'model', 'line', 'flight', 'debut', 'record', 'law', 'degree', 'air', 'version', 'route', 'show', 'research', 'way', 'centre', 'conference', 'season', 'medal', 'order', 'style', 'language', 'secretary', 'center', 'class', 'master', 'piece', 'trip', 'science', 'position', 'letter', 'play', 'education', 'president', 'capital', 'building', 'piano', 'radio', 'night', 'edition', 'writer', 'prize', 'hotel', 'court', 'story', 'game', 'interest', 'team', 'composer', 'appearance', 'area', 'head', 'venue', 'designer', 'scene', 'train', 'garden', 'newspaper', 'bank', 'system', 'affair', 'location', 'ambassador', 'return', 'publication', 'department', 'power', 'sister', 'army', 'station', 'market', 'firm', 'editor', 'church', 'dance', 'minister', 'party', 'sculpture', 'town', 'hospital', 'singer', 'addition', 'guest', 'press', 'example', 'competition', 'meeting', 'peace', 'hall', 'network', 'store', 'husband', 'force', 'figure', 'recording', 'video', 'novel', 'gold', 'treaty', 'course', 'salon', 'plan', 'airline', 'teacher', 'movement', 'passenger', 'institution', 'development', 'railway', 'operation', 'money', 'parent', 'airport', 'premiere', 'idea', 'point', 'visit', 'paper', 'aircraft', 'critic', 'queen', 'subject', 'management', 'act', 'article', 'love', 'economic', 'officer', 'review', 'support', 'embassy', 'girl', 'culture', 'program', 'revolution', 'hour', 'post', 'training', 'right', 'news', 'use', 'travel', 'hand', 'theater', 'institute', 'fellow', 'branch', 'park', 'result', 'exposition', 'activity', 'space', 'palace', 'musician', 'empire', 'author', 'influence', 'medicine', 'exile', 'date', 'partner', 'trade', 'writing', 'translation', 'marriage', 'picture', 'commission', 'industry', 'field', 'room', 'architecture', 'term', 'couple', 'audience', 'spring', 'nation', 'co', 'television', 'mission', 'jean', 'correspondent', 'architect', 'composition', 'release', 'medium', 'track', 'road', 'decade', 'drawing', 'journal', 'form', 'character', 'actor', 'leader', 'attack', 'board', 'literature', 'star', 'copy', 'scholarship', 'relationship', 'island', 'sale', 'conductor', 'issue', 'journalist', 'experience', 'committee', 'oil', 'organization', 'founder', 'photography', 'view', 'practice', 'library', 'manuscript', 'winter', 'west', 'landscape', 'agency', 'agent', 'community', 'physician', 'today', 'match', 'prince', 'case', 'region', 'channel', 'journey', 'lecture', 'volume', 'association', 'foundation', 'set', 'section', 'opening', 'tournament', 'job', 'campaign', 'report', 'jazz', 'shop', 'ship', 'photographer', 'relation', 'player', 'minute', 'part', 'material', 'dancer', 'police', 'authority', 'brand', 'account', 'image', 'voice', 'label', 'league', 'exchange', 'tower', 'car', 'information', 'policy', 'body', 'print', 'poet', 'race', 'solo', 'estate', 'programme', 'covent', 'staff', 'effort', 'attempt', 'water', 'saint', 'land', 'sculptor', 'collaboration', 'assistant', 'destination', 'control', 'council', 'representative', 'reputation', 'contact', 'fund', 'photograph', 'residence', 'producer', 'contract', 'chamber', 'rest', 'attention', 'restaurant', 'agreement', 'manager', 'boy', 'speed', 'publisher', 'type', 'engineer', 'north', 'connection', 'fall', 'battle', 'theme', 'olympic', 'text', 'beginning', 'merchant', 'technique', 'poem', 'fact', 'health', 'protest', 'pupil', 'philosophy', 'feature', 'pianist', 'action', 'rock', 'actress', 'cologne', 'championship', 'union', 'doctor', 'drama', 'poetry', 'page', 'property', 'source', 'score', 'circle', 'violin', 'recital', 'cover', 'half', 'opportunity', 'era', 'site', 'level', 'chair', 'river', 'public', 'glass', 'charge', 'division', 'construction', 'effect', 'scholar', 'evening', 'headquarters', 'teaching', 'process', 'outbreak', 'thing', 'bronze', 'delegation', 'independence', 'sea', 'factory', 'word', 'concerto', 'instrument', 'variety', 'self', 'district', 'light', 'soloist', 'establishment', 'change', 'organisation', 'owner', 'range', 'lady', 'session', 'interview', 'negotiation', 'coast', 'historian', 'surgeon', 'investment', 'demand', 'youth', 'list', 'parliament', 'essay', 'person', 'chief', 'occasion', 'village', 'pop', 'rail', 'photo', 'resistance', 'comedy', 'direction', 'singing', 'worker', 'movie', 'ground', 'intelligence', 'population', 'stay', 'trial', 'recognition', 'diplomat', 'cast', 'eye', 'price', 'problem', 'technology', 'machine', 'transport', 'documentary', 'bridge', 'finance', 'troop', 'fellowship', 'collector', 'conservatory', 'fire', 'run', 'note', 'autumn', 'tv', 'dealer', 'march', 'lecturer', 'display', 'product', 'ensemble', 'alliance', 'continent', 'introduction', 'creation', 'installation', 'generation', 'chairman', 'mile', 'faculty', 'soldier', 'bar', 'talent', 'doctorate', 'vice', 'vogue', 'engine', 'presence', 'engineering', 'birth', 'quality', 'colour', 'traffic', 'scale', 'childhood', 'honour', 'condition', 'port', 'partnership', 'communication', 'morning', 'archive', 'coach', 'delegate', 'costume', 'arrival', 'illustration', 'reason', 'south', 'exhibit', 'security', 'chess', 'wall', 'arena', 'friendship', 'east', 'camp', 'revival', 'performer', 'horse', 'ally', 'decision', 'cinema', 'cathedral', 'visitor', 'invasion', 'final', 'workshop', 'leg', 'tunnel', 'crisis', 'general', 'paris', 'heart', 'engagement', 'comique', 'wood', 'victory', 'help', 'method', 'associate', 'border', 'anniversary', 'prison', 'publishing', 'structure', 'arm', 'message', 'champion', 'retrospective', 'start', 'territory', 'fleet', 'administration', 'wing', 'convention', 'memoir', 'cost', 'occupation', 'basis', 'invitation', 'foot', 'talk', 'politic', 'color', 'theory', 'matter', 'animal', 'dress', 'seat', 'offer', 'banking', 'bachelor', 'rule', 'colony', 'purpose', 'honor', 'iron', 'appointment', 'advertising', 'single', 'thesis', 'republic', 'round', 'silver', 'auction', 'fair', 'size', 'entry', 'citizen', 'ticket', 'patron', 'winner', 'luxury', 'face', 'sketch', 'walker', 'royal', 'lover', 'stone', 'contribution', 'hope', 'distance', 'resident', 'facility', 'tradition', 'hague', 'repertoire', 'food', 'sport', 'nature', 'base', 'popularity', 'skill', 'standard', 'detail', 'response', 'situation', 'cabinet', 'client', 'artwork', 'organ', 'rank', 'concept', 'operator', 'proposal', 'legation', 'cause', 'commander', 'grant', 'election', 'unit', 'platform', 'plot', 'failure', 'knowledge', 'correspondence', 'beauty', 'employee', 'plant', 'diploma', 'official', 'captain', 'craft', 'quarter', 'departure', 'cape', 'province', 'princess', 'arrangement', 'need', 'bid', 'surgery', 'boat', 'object', 'soprano', 'living', 'origin', 'sorbonne', 'economy', 'pound', 'colleague', 'wedding', 'pair', 'diamond', 'apartment', 'acclaim', 'status', 'length', 'value', 'total', 'marathon', 'et', 'ottoman', 'stock', 'maker', 'conflict', 'demonstration', 'map', 'lesson', 'deal', 'governor', 'box', 'german', 'm', 'bishop', 'residency', 'question', 'reference', 'runway', 'uncle', 'ministry', 'stop', 'politician', 'link', 'command', 'window', 'kind', 'loss', 'access', 'patent', 'cemetery', 'laboratory', 'furniture', 'guitar', 'catalogue', 'lead', 'mill', 'fan', 'sound', 'entertainment', 'turn', 'aviation', 'expedition', 'flower', 'statue', 'debt', 'banker', 'adaptation', 'episode', 'fortune', 'bath', 'evidence', 'cousin', 'commissioner', 'boutique', 'share', 'goal', 'carrier', 'charity', 'string', 'engraving', 'curator', 'watercolour', 'behalf', 'crew', 'broadcast', 'lot', 'lawyer', 'grandfather', 'leadership', 'dream', 'freedom', 'request', 'duty', 'violinist', 'capacity', 'vol', 'thousand', 'genre', 'mind', 'focus', 'reporter', 'crowd', 'hub', 'name', 'good', 'clothing', 'speech', 'passion', 'prisoner', 'tenor', 'majority', 'prix', 'presentation', 'chapter', 'chef', 'monument', 'mountain', 'moment', 'crown', 'defence', 'ring', 'subsidiary', 'guy', 'scientist', 'choice', 'kingdom', 'camera', 'mail', 'spirit', 'bond', 'km', 'claim', 'pavilion', 'chorus', 'ceremony', 'growth', 'hill', 'document', 'criticism', 'wine', 'sense', 'guild', 'widow', 'relief', 'specimen', 'manner', 'duo', 'element', 'venture', 'pilot', 'card', 'bus', 'retirement', 'poster', 'crime', 'approach', 'identity', 'reform', 'cycle', 'host', 'celebrity', 'survey', 'mayor', 'steel', 'climate', 'couture', 'campus', 'consul', 'religion', 'guide', 'emperor', 'passage', 'cent', 'charter', 'customer', 'purchase', 'vehicle', 'fame', 'voyage', 'birthday', 'circuit', 'mathematic', 'door', 'count', 'lyric', 'progress', 'lack', 'trend', 'tale', 'acquisition', 'lieutenant', 'graduate', 'thank', 'murder', 'plane', 'restoration', 'tourist', 'chance', 'opposition', 'candidate', 'manufacturer', 'holiday', 'motion', 'metre', 'duchess', 'step', 'biennale', 'stadium', 'shoe', 'defeat', 'opinion', 'anatomy', 'quartet', 'guardian', 'deputy', 'memory', 'scheme', 'pressure', 'incident', 'seine', 'screen', 'metal', 'supporter', 'printing', 'clerk', 'trio', 'bust', 'fiction', 'setting', 'refugee', 'jet', 'difficulty', 'distribution', 'discussion', 'biography', 'expansion', 'lake', 'settlement', 'instruction', 'experiment', 'disease', 'lifetime', 'taste', 'regime', 'future', 'membership', 'journalism', 'trading', 'der', 'arrest', 'advice', 'dancing', 'floor', 'choir', 'interior', 'notice', 'aspect', 'selection', 'background', 'bird', 'inspiration', 'chart', 'dome', 'panel', 'mention', 'graduation', 'suburb', 'discovery', 'sign', 'physics', 'task', 'bomb', 'companion', 'cabaret', 'classic', 'bass', 'participant', 'permission', 'celebration', 'sun', 'county', 'telegraph', 'chemistry', 'hundred', 'marketing', 'mural', 'employment', 'nightclub', 'globe', 'mark', 'loan', 'flag', 'mean', 'formation']\n"
     ]
    }
   ],
   "source": [
    "words = [x[0] for x in most_common[:1000]]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0a2ae9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "textstring = \"Napoleon as Mars the Peacemaker had its inception after Canova was hired to make a bust of Napoleon in 1802. The statue was begun in 1802, with Napoleon requesting to be shown in a French General's uniform, Canova rejected this, insisting on an allusion to Mars, the Roman god of War. It was completed in 1806. In 1811, the statue arrived in Paris, but not installed; neither was its bronze copy in the Foro Napoleonico in Milan. In 1815, the original went to the Duke of Wellington, after his victory at Waterloo against Napoleon. \"\n",
    "\n",
    "# words = ['peacemaker', 'inception', 'hire', 'bust', 'statue', 'begin', 'request', 'show', 'french', 'general', 'uniform', 'reject', 'insist', 'allusion', 'roman', 'war', 'complete', 'statue', 'arrive', 'instal', 'bronze', 'copy', 'original', 'go', 'victory']\n",
    "words = ['peacemaker', 'inception', 'bust', 'statue', 'french', 'general', 'uniform', 'allusion', 'roman', 'war', 'statue', 'bronze', 'copy', 'original', 'victory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "25ba21c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# words = ['red', 'card', 'club', 'world', 'championship', 'necaxa', 'time', 'real', 'yellow', 'card', 'red', 'card', 'red', 'card', 'red', 'card', 'la', 'galaxy', 'home', 'defeat', 'sounder', 'red', 'card', 'injury', 'time', 'match', 'competitive', 'game', 'red', 'card', 'match', 'average']\n",
    "#words = ['red', 'card', 'come', 'club', 'world', 'championship', 'necaxa', 'time', 'real', 'amass', 'yellow', 'card', 'red', 'card', 'receive', 'red', 'card', 'red', 'card', 'la', 'galaxy', 'come', 'home', 'defeat', 'sounder', 'receive', 'red', 'card', 'pick', 'injury', 'time', 'match', 'play', 'competitive', 'game', 'receive', 'red', 'card', 'match', 'average']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f2355eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "textstring = \"David Robert Joseph Beckham (; born 2 May 1975) is an English former professional footballer, the current president &amp; co-owner of Inter Miami CF and co-owner of Salford City. He played for Manchester United, Preston North End (on loan), Real Madrid, AC Milan (on loan), LA Galaxy, Paris Saint-Germain and the England national team, for which he held the appearance record for an outfield player until 2016. He is the first English player to win league titles in four countries: England, Spain, the United States and France. He retired in May 2013 after a 20-year career, during which he won 19 major trophies.\"\n",
    "words = ['bear', 'english', 'professional', 'footballer', 'current', 'president', 'amp', 'co', 'owner', 'co', 'owner', 'play', 'loan', 'loan', 'hold', 'appearance', 'record', 'outfield', 'player', 'english', 'player', 'win', 'league', 'title', 'country', 'retire', 'year', 'career', 'win', 'major', 'trophy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "dbc690e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "textstring = \"In 1872, Abbott went abroad to study with Antonio Sangiovanni in Milan. This was followed by further studies with Mathilde Marchesi, Pierre François Wartel and Enrico Delle Sedie in Paris. She appeared in several productions in Paris, earning rave reviews for her fine soprano voice. She was awarded a contract with the Royal Opera in London and made her début at Covent Garden as Marie in 'La Fille du régiment' in 1876. However, her contract was cancelled shortly thereafter when she refused to sing Violetta from Verdi's 'La Traviata' on moral grounds. That same year she secretly married Eugene Wetherell (d. 1889) and they returned to the United States, where she remained for the rest of her life.\"\n",
    "words = ['go', 'study', 'follow', 'study', 'sedie', 'appear', 'production', 'earn', 'rave', 'review', 'fine', 'soprano', 'voice', 'award', 'contract', 'royal', 'opera', 'début', 'covent', 'garden', 'régiment', 'contract', 'cancel', 'refuse', 'sing', 'violetta', 'moral', 'ground', 'year', 'marry', 'return', 'remain', 'rest', 'life']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "671999a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "e5bb71ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: \t\tgo\n",
      "analysis: \tnot enough difference\n",
      "scores:\n",
      "\t----category----          ----score----\n",
      "\twar        \t\t0.4399181008338928\n",
      "\teducation  \t\t0.4335162937641144\n",
      "\tsport      \t\t0.4327922761440277\n",
      "\tculture    \t\t0.4205860197544098\n",
      "\tfashion    \t\t0.415298730134964\n",
      "\tpolitics   \t\t0.38997897505760193\n",
      "\n",
      "**left out due to ambiguity**\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "word: \t\tstudy\n",
      "analysis: \tenough difference\n",
      "scores:\n",
      "\t----category----          ----score----\n",
      "\teducation  \t\t0.574546754360199\n",
      "\tculture    \t\t0.4654148817062378\n",
      "\tpolitics   \t\t0.37829726934432983\n",
      "\twar        \t\t0.3699481189250946\n",
      "\tfashion    \t\t0.32155609130859375\n",
      "\tsport      \t\t0.3135829269886017\n",
      "\n",
      "\n",
      "==> \tword: study, \n",
      "\tcategory:, education, \n",
      "\tsimilarity score:, 0.574546754360199\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "word: \t\tfollow\n",
      "analysis: \tenough difference\n",
      "scores:\n",
      "\t----category----          ----score----\n",
      "\tfashion    \t\t0.43281760811805725\n",
      "\teducation  \t\t0.4069565534591675\n",
      "\tculture    \t\t0.3794364929199219\n",
      "\tpolitics   \t\t0.37496280670166016\n",
      "\twar        \t\t0.3284284174442291\n",
      "\tsport      \t\t0.32283997535705566\n",
      "\n",
      "\n",
      "==> \tword: follow, \n",
      "\tcategory:, fashion, \n",
      "\tsimilarity score:, 0.43281760811805725\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "word: \t\tstudy\n",
      "analysis: \tenough difference\n",
      "scores:\n",
      "\t----category----          ----score----\n",
      "\teducation  \t\t0.574546754360199\n",
      "\tculture    \t\t0.4654148817062378\n",
      "\tpolitics   \t\t0.37829726934432983\n",
      "\twar        \t\t0.3699481189250946\n",
      "\tfashion    \t\t0.32155609130859375\n",
      "\tsport      \t\t0.3135829269886017\n",
      "\n",
      "\n",
      "==> \tword: study, \n",
      "\tcategory:, education, \n",
      "\tsimilarity score:, 0.574546754360199\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "word: \t\tsedie\n",
      "analysis: \tenough difference\n",
      "scores:\n",
      "\t----category----          ----score----\n",
      "\tsport      \t\t-0.02894185297191143\n",
      "\tfashion    \t\t-0.10504622757434845\n",
      "\tpolitics   \t\t-0.11453201621770859\n",
      "\tculture    \t\t-0.16073711216449738\n",
      "\teducation  \t\t-0.17558470368385315\n",
      "\twar        \t\t-0.17622561752796173\n",
      "\n",
      "**left out due to low similarity score**\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "word: \t\tappear\n",
      "analysis: \tnot enough difference\n",
      "scores:\n",
      "\t----category----          ----score----\n",
      "\twar        \t\t0.37558913230895996\n",
      "\tfashion    \t\t0.3740485608577728\n",
      "\tpolitics   \t\t0.34684789180755615\n",
      "\tculture    \t\t0.3423249423503876\n",
      "\teducation  \t\t0.3407585918903351\n",
      "\tsport      \t\t0.29354390501976013\n",
      "\n",
      "**left out due to ambiguity**\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "word: \t\tproduction\n",
      "analysis: \tnot enough difference\n",
      "scores:\n",
      "\t----category----          ----score----\n",
      "\teducation  \t\t0.41426634788513184\n",
      "\tculture    \t\t0.4058414399623871\n",
      "\tfashion    \t\t0.367304265499115\n",
      "\twar        \t\t0.35513514280319214\n",
      "\tsport      \t\t0.29604971408843994\n",
      "\tpolitics   \t\t0.2509172558784485\n",
      "\n",
      "**left out due to ambiguity**\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "word: \t\tearn\n",
      "analysis: \tenough difference\n",
      "scores:\n",
      "\t----category----          ----score----\n",
      "\teducation  \t\t0.4088855981826782\n",
      "\tsport      \t\t0.29583409428596497\n",
      "\tfashion    \t\t0.263887494802475\n",
      "\twar        \t\t0.2543976902961731\n",
      "\tculture    \t\t0.2473546415567398\n",
      "\tpolitics   \t\t0.20777419209480286\n",
      "\n",
      "\n",
      "==> \tword: earn, \n",
      "\tcategory:, education, \n",
      "\tsimilarity score:, 0.4088855981826782\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "word: \t\trave\n",
      "analysis: \tenough difference\n",
      "scores:\n",
      "\t----category----          ----score----\n",
      "\tculture    \t\t0.32954198122024536\n",
      "\tfashion    \t\t0.3277128040790558\n",
      "\tsport      \t\t0.25598567724227905\n",
      "\twar        \t\t0.1920289695262909\n",
      "\tpolitics   \t\t0.1779143512248993\n",
      "\teducation  \t\t0.14914321899414062\n",
      "\n",
      "\n",
      "==> \tword: rave, \n",
      "\tcategory:, culture, \n",
      "\tsimilarity score:, 0.32954198122024536\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "word: \t\treview\n",
      "analysis: \tenough difference\n",
      "scores:\n",
      "\t----category----          ----score----\n",
      "\teducation  \t\t0.4184594452381134\n",
      "\twar        \t\t0.3825662136077881\n",
      "\tsport      \t\t0.35832151770591736\n",
      "\tfashion    \t\t0.3476109802722931\n",
      "\tculture    \t\t0.33571818470954895\n",
      "\tpolitics   \t\t0.3198053240776062\n",
      "\n",
      "\n",
      "==> \tword: review, \n",
      "\tcategory:, education, \n",
      "\tsimilarity score:, 0.4184594452381134\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "word: \t\tfine\n",
      "analysis: \tnot enough difference\n",
      "scores:\n",
      "\t----category----          ----score----\n",
      "\tfashion    \t\t0.43580445647239685\n",
      "\tculture    \t\t0.40363171696662903\n",
      "\teducation  \t\t0.3872268795967102\n",
      "\tsport      \t\t0.37748831510543823\n",
      "\twar        \t\t0.3449231684207916\n",
      "\tpolitics   \t\t0.2939656376838684\n",
      "\n",
      "**left out due to ambiguity**\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "word: \t\tsoprano\n",
      "analysis: \tnot enough difference\n",
      "scores:\n",
      "\t----category----          ----score----\n",
      "\tfashion    \t\t0.11465365439653397\n",
      "\tsport      \t\t0.07535946369171143\n",
      "\teducation  \t\t0.0676107183098793\n",
      "\twar        \t\t0.054162297397851944\n",
      "\tpolitics   \t\t0.04593717306852341\n",
      "\tculture    \t\t0.03608061000704765\n",
      "\n",
      "**left out due to ambiguity**\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "word: \t\tvoice\n",
      "analysis: \tnot enough difference\n",
      "scores:\n",
      "\t----category----          ----score----\n",
      "\teducation  \t\t0.3474310338497162\n",
      "\tpolitics   \t\t0.3154948353767395\n",
      "\twar        \t\t0.31364452838897705\n",
      "\tculture    \t\t0.2856099009513855\n",
      "\tfashion    \t\t0.26610350608825684\n",
      "\tsport      \t\t0.2266775667667389\n",
      "\n",
      "**left out due to ambiguity**\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "word: \t\taward\n",
      "analysis: \tenough difference\n",
      "scores:\n",
      "\t----category----          ----score----\n",
      "\teducation  \t\t0.47735095024108887\n",
      "\tfashion    \t\t0.3811494708061218\n",
      "\tculture    \t\t0.36517393589019775\n",
      "\tsport      \t\t0.36355650424957275\n",
      "\twar        \t\t0.3137085735797882\n",
      "\tpolitics   \t\t0.2567768394947052\n",
      "\n",
      "\n",
      "==> \tword: award, \n",
      "\tcategory:, education, \n",
      "\tsimilarity score:, 0.47735095024108887\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "word: \t\tcontract\n",
      "analysis: \tenough difference\n",
      "scores:\n",
      "\t----category----          ----score----\n",
      "\teducation  \t\t0.3552599549293518\n",
      "\twar        \t\t0.3262999951839447\n",
      "\tsport      \t\t0.3012050986289978\n",
      "\tfashion    \t\t0.25959959626197815\n",
      "\tculture    \t\t0.23442429304122925\n",
      "\tpolitics   \t\t0.22187085449695587\n",
      "\n",
      "\n",
      "==> \tword: contract, \n",
      "\tcategory:, education, \n",
      "\tsimilarity score:, 0.3552599549293518\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "word: \t\troyal\n",
      "analysis: \tnot enough difference\n",
      "scores:\n",
      "\t----category----          ----score----\n",
      "\tsport      \t\t0.3869764804840088\n",
      "\twar        \t\t0.3715934753417969\n",
      "\tfashion    \t\t0.3601175844669342\n",
      "\teducation  \t\t0.32127845287323\n",
      "\tculture    \t\t0.31529736518859863\n",
      "\tpolitics   \t\t0.24646902084350586\n",
      "\n",
      "**left out due to ambiguity**\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "word: \t\topera\n",
      "analysis: \tnot enough difference\n",
      "scores:\n",
      "\t----category----          ----score----\n",
      "\tfashion    \t\t0.293753981590271\n",
      "\tculture    \t\t0.2717922031879425\n",
      "\twar        \t\t0.2661792039871216\n",
      "\tsport      \t\t0.25019925832748413\n",
      "\teducation  \t\t0.24190029501914978\n",
      "\tpolitics   \t\t0.20343618094921112\n",
      "\n",
      "**left out due to ambiguity**\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "word: \t\tdébut\n",
      "analysis: \tnot enough difference\n",
      "scores:\n",
      "\t----category----          ----score----\n",
      "\tfashion    \t\t0.06844079494476318\n",
      "\tsport      \t\t0.06463064253330231\n",
      "\twar        \t\t0.03311813250184059\n",
      "\tculture    \t\t-0.0010597569635137916\n",
      "\teducation  \t\t-0.046695366501808167\n",
      "\tpolitics   \t\t-0.062075261026620865\n",
      "\n",
      "**left out due to ambiguity**\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "word: \t\tcovent\n",
      "analysis: \tenough difference\n",
      "scores:\n",
      "\t----category----          ----score----\n",
      "\tfashion    \t\t0.18027999997138977\n",
      "\tsport      \t\t0.06646834313869476\n",
      "\tculture    \t\t0.05949998274445534\n",
      "\twar        \t\t0.027659215033054352\n",
      "\teducation  \t\t0.016957422718405724\n",
      "\tpolitics   \t\t0.014461738057434559\n",
      "\n",
      "\n",
      "==> \tword: covent, \n",
      "\tcategory:, fashion, \n",
      "\tsimilarity score:, 0.18027999997138977\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "word: \t\tgarden\n",
      "analysis: \tenough difference\n",
      "scores:\n",
      "\t----category----          ----score----\n",
      "\tfashion    \t\t0.3839989900588989\n",
      "\tculture    \t\t0.3382722735404968\n",
      "\tsport      \t\t0.31381720304489136\n",
      "\twar        \t\t0.3078462481498718\n",
      "\teducation  \t\t0.2978126108646393\n",
      "\tpolitics   \t\t0.2447652816772461\n",
      "\n",
      "\n",
      "==> \tword: garden, \n",
      "\tcategory:, fashion, \n",
      "\tsimilarity score:, 0.3839989900588989\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "word: \t\trégiment\n",
      "analysis: \tenough difference\n",
      "scores:\n",
      "\t----category----          ----score----\n",
      "\twar        \t\t-0.013120107352733612\n",
      "\tsport      \t\t-0.06183101236820221\n",
      "\tfashion    \t\t-0.07297692447900772\n",
      "\tculture    \t\t-0.07816976308822632\n",
      "\tpolitics   \t\t-0.10391729325056076\n",
      "\teducation  \t\t-0.11371542513370514\n",
      "\n",
      "**left out due to low similarity score**\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "word: \t\tcontract\n",
      "analysis: \tenough difference\n",
      "scores:\n",
      "\t----category----          ----score----\n",
      "\teducation  \t\t0.3552599549293518\n",
      "\twar        \t\t0.3262999951839447\n",
      "\tsport      \t\t0.3012050986289978\n",
      "\tfashion    \t\t0.25959959626197815\n",
      "\tculture    \t\t0.23442429304122925\n",
      "\tpolitics   \t\t0.22187085449695587\n",
      "\n",
      "\n",
      "==> \tword: contract, \n",
      "\tcategory:, education, \n",
      "\tsimilarity score:, 0.3552599549293518\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "word: \t\tcancel\n",
      "analysis: \tnot enough difference\n",
      "scores:\n",
      "\t----category----          ----score----\n",
      "\teducation  \t\t0.2327539026737213\n",
      "\twar        \t\t0.23076455295085907\n",
      "\tpolitics   \t\t0.2031680792570114\n",
      "\tsport      \t\t0.19113577902317047\n",
      "\tculture    \t\t0.1575518101453781\n",
      "\tfashion    \t\t0.14929428696632385\n",
      "\n",
      "**left out due to ambiguity**\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "word: \t\trefuse\n",
      "analysis: \tnot enough difference\n",
      "scores:\n",
      "\t----category----          ----score----\n",
      "\twar        \t\t0.31992730498313904\n",
      "\tculture    \t\t0.3195456862449646\n",
      "\tpolitics   \t\t0.2941931486129761\n",
      "\teducation  \t\t0.29134196043014526\n",
      "\tsport      \t\t0.22885946929454803\n",
      "\tfashion    \t\t0.22061926126480103\n",
      "\n",
      "**left out due to ambiguity**\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "word: \t\tsing\n",
      "analysis: \tnot enough difference\n",
      "scores:\n",
      "\t----category----          ----score----\n",
      "\twar        \t\t0.2669313848018646\n",
      "\teducation  \t\t0.22226914763450623\n",
      "\tfashion    \t\t0.21938540041446686\n",
      "\tculture    \t\t0.21828573942184448\n",
      "\tsport      \t\t0.20453408360481262\n",
      "\tpolitics   \t\t0.19006194174289703\n",
      "\n",
      "**left out due to ambiguity**\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "word: \t\tvioletta\n",
      "analysis: \tnot enough difference\n",
      "scores:\n",
      "\t----category----          ----score----\n",
      "\twar        \t\t-0.029897276312112808\n",
      "\tfashion    \t\t-0.033534396439790726\n",
      "\tpolitics   \t\t-0.07794918119907379\n",
      "\teducation  \t\t-0.08032313734292984\n",
      "\tsport      \t\t-0.13932912051677704\n",
      "\tculture    \t\t-0.1644349992275238\n",
      "\n",
      "**left out due to ambiguity**\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "word: \t\tmoral\n",
      "analysis: \tnot enough difference\n",
      "scores:\n",
      "\t----category----          ----score----\n",
      "\tpolitics   \t\t0.45729753375053406\n",
      "\tculture    \t\t0.44830459356307983\n",
      "\twar        \t\t0.4074634313583374\n",
      "\teducation  \t\t0.3912127614021301\n",
      "\tfashion    \t\t0.2952975034713745\n",
      "\tsport      \t\t0.22927294671535492\n",
      "\n",
      "**left out due to ambiguity**\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "word: \t\tground\n",
      "analysis: \tenough difference\n",
      "scores:\n",
      "\t----category----          ----score----\n",
      "\twar        \t\t0.41804057359695435\n",
      "\teducation  \t\t0.33826547861099243\n",
      "\tculture    \t\t0.32779166102409363\n",
      "\tpolitics   \t\t0.3180716931819916\n",
      "\tsport      \t\t0.3144012689590454\n",
      "\tfashion    \t\t0.2590726315975189\n",
      "\n",
      "\n",
      "==> \tword: ground, \n",
      "\tcategory:, war, \n",
      "\tsimilarity score:, 0.41804057359695435\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "word: \t\tyear\n",
      "analysis: \tenough difference\n",
      "scores:\n",
      "\t----category----          ----score----\n",
      "\teducation  \t\t0.49935826659202576\n",
      "\twar        \t\t0.4512106478214264\n",
      "\tfashion    \t\t0.4387242794036865\n",
      "\tsport      \t\t0.41323035955429077\n",
      "\tculture    \t\t0.3808120787143707\n",
      "\tpolitics   \t\t0.30827268958091736\n",
      "\n",
      "\n",
      "==> \tword: year, \n",
      "\tcategory:, education, \n",
      "\tsimilarity score:, 0.49935826659202576\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "word: \t\tmarry\n",
      "analysis: \tnot enough difference\n",
      "scores:\n",
      "\t----category----          ----score----\n",
      "\tfashion    \t\t0.27107807993888855\n",
      "\tculture    \t\t0.2612100839614868\n",
      "\twar        \t\t0.2351105660200119\n",
      "\tpolitics   \t\t0.23376786708831787\n",
      "\teducation  \t\t0.2334381341934204\n",
      "\tsport      \t\t0.17151206731796265\n",
      "\n",
      "**left out due to ambiguity**\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "word: \t\treturn\n",
      "analysis: \tenough difference\n",
      "scores:\n",
      "\t----category----          ----score----\n",
      "\twar        \t\t0.406259685754776\n",
      "\teducation  \t\t0.3676384687423706\n",
      "\tculture    \t\t0.3560667037963867\n",
      "\tfashion    \t\t0.3142957091331482\n",
      "\tsport      \t\t0.310580313205719\n",
      "\tpolitics   \t\t0.303750604391098\n",
      "\n",
      "\n",
      "==> \tword: return, \n",
      "\tcategory:, war, \n",
      "\tsimilarity score:, 0.406259685754776\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "word: \t\tremain\n",
      "analysis: \tnot enough difference\n",
      "scores:\n",
      "\t----category----          ----score----\n",
      "\tculture    \t\t0.4217946231365204\n",
      "\twar        \t\t0.3963985741138458\n",
      "\tpolitics   \t\t0.3933825194835663\n",
      "\teducation  \t\t0.39100000262260437\n",
      "\tfashion    \t\t0.31544801592826843\n",
      "\tsport      \t\t0.3121059238910675\n",
      "\n",
      "**left out due to ambiguity**\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "word: \t\trest\n",
      "analysis: \tenough difference\n",
      "scores:\n",
      "\t----category----          ----score----\n",
      "\twar        \t\t0.4607382118701935\n",
      "\tculture    \t\t0.4306408166885376\n",
      "\teducation  \t\t0.38297367095947266\n",
      "\tpolitics   \t\t0.3801937401294708\n",
      "\tfashion    \t\t0.34989652037620544\n",
      "\tsport      \t\t0.34565532207489014\n",
      "\n",
      "\n",
      "==> \tword: rest, \n",
      "\tcategory:, war, \n",
      "\tsimilarity score:, 0.4607382118701935\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "word: \t\tlife\n",
      "analysis: \tenough difference\n",
      "scores:\n",
      "\t----category----          ----score----\n",
      "\tculture    \t\t0.5718253254890442\n",
      "\teducation  \t\t0.5466377139091492\n",
      "\twar        \t\t0.482273668050766\n",
      "\tpolitics   \t\t0.47423335909843445\n",
      "\tfashion    \t\t0.4576948583126068\n",
      "\tsport      \t\t0.42960867285728455\n",
      "\n",
      "\n",
      "==> \tword: life, \n",
      "\tcategory:, culture, \n",
      "\tsimilarity score:, 0.5718253254890442\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "words: ['go', 'study', 'follow', 'study', 'sedie', 'appear', 'production', 'earn', 'rave', 'review', 'fine', 'soprano', 'voice', 'award', 'contract', 'royal', 'opera', 'début', 'covent', 'garden', 'régiment', 'contract', 'cancel', 'refuse', 'sing', 'violetta', 'moral', 'ground', 'year', 'marry', 'return', 'remain', 'rest', 'life'] \n",
      "\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 12 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('study', (0.574546754360199, 'education')),\n",
       " ('follow', (0.43281760811805725, 'fashion')),\n",
       " ('study', (0.574546754360199, 'education')),\n",
       " ('earn', (0.4088855981826782, 'education')),\n",
       " ('rave', (0.32954198122024536, 'culture')),\n",
       " ('review', (0.4184594452381134, 'education')),\n",
       " ('award', (0.47735095024108887, 'education')),\n",
       " ('contract', (0.3552599549293518, 'education')),\n",
       " ('covent', (0.18027999997138977, 'fashion')),\n",
       " ('garden', (0.3839989900588989, 'fashion')),\n",
       " ('contract', (0.3552599549293518, 'education')),\n",
       " ('ground', (0.41804057359695435, 'war')),\n",
       " ('year', (0.49935826659202576, 'education')),\n",
       " ('return', (0.406259685754776, 'war')),\n",
       " ('rest', (0.4607382118701935, 'war')),\n",
       " ('life', (0.5718253254890442, 'culture'))]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "verbose1, verbose2 = False, True\n",
    "similar_categories = []\n",
    "similar_categories_extended = []\n",
    "for word in words:\n",
    "    closeness = []\n",
    "    if verbose1 or verbose2:\n",
    "        print(f\"word: \\t\\t{word}\")\n",
    "    for category in descriptive_keywords:\n",
    "        summed_similarity = 0\n",
    "        for keyword in category:\n",
    "            keyword_vector = embeddings_dict[keyword]        \n",
    "            word_vector = embeddings_dict[word]\n",
    "            value = 1 - cosine(keyword_vector, word_vector)\n",
    "            summed_similarity += value\n",
    "            break\n",
    "        \n",
    "        normalized_similarity = summed_similarity/len(category)\n",
    "        normalized_similarity = summed_similarity\n",
    "        closeness.append((normalized_similarity, category[0]))\n",
    "        \n",
    "        if verbose1:\n",
    "            print('___________________________')\n",
    "            print('===>', '\\tcategory:', category[0], '\\n\\tsimilarity:', normalized_similarity, f\"\\n\\tkeywords: {category}\", )\n",
    "     \n",
    "    similar_category = max(closeness)\n",
    "    \n",
    "    sortedcat = sorted(closeness, key=lambda item: item[0], reverse=True)\n",
    "    if (sortedcat[0][0] - 0.05) > sortedcat[2][0]:\n",
    "        allowed = True\n",
    "        print(f\"analysis: \\tenough difference\\nscores:\")\n",
    "        print(\"\\t----category----          ----score----\")\n",
    "        for i in sortedcat:\n",
    "            print(f\"\\t{i[1]:<10s} \\t\\t{i[0]}\")\n",
    "        print()\n",
    "    else:\n",
    "        allowed = False\n",
    "        print(f\"analysis: \\tnot enough difference\\nscores:\")\n",
    "        print(\"\\t----category----          ----score----\")\n",
    "        for i in sortedcat:\n",
    "            print(f\"\\t{i[1]:<10s} \\t\\t{i[0]}\")\n",
    "        print()\n",
    "    if similar_category[0] > 0.1 and allowed:\n",
    "        similar_categories.append((word, similar_category))\n",
    "#         if (sortedcat[0][0] - 0.05 < sortedcat[2][0]):\n",
    "#             similar_categories_extended.append((word, sortedcat[0:3]))\n",
    "#         elif (sortedcat[0][0] - 0.05 < sortedcat[1][0]):\n",
    "#             similar_categories_extended.append((word, sortedcat[0:2]))\n",
    "#         else:\n",
    "#             print('xxx', word, sortedcat[0])\n",
    "#             similar_categories_extended.append((word, [sortedcat[0]]))\n",
    "        if verbose2:\n",
    "            #print('category similarity:')\n",
    "            # pprint(sorted(closeness, key=lambda x: x[0], reverse=True))\n",
    "            print()\n",
    "            print(f\"==> \\tword: {word}, \\n\\tcategory:, {similar_category[1]}, \\n\\tsimilarity score:, {similar_category[0]}\")\n",
    "    else:\n",
    "        reason = 'ambiguity' if not allowed else 'low similarity score'\n",
    "        print(f\"**left out due to {reason}**\")\n",
    "    \n",
    "\n",
    "    print('='*100)\n",
    "    print('\\n')\n",
    "\n",
    "print('\\nwords:', words, '\\n')\n",
    "\n",
    "similar_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "f574811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"football\", \"club\", \"archery\", \"athlete\", \"ball\", \"biking\", \"student\", 'catwalk', 'brainfreeze', 'nerd', 'geek', \n",
    "         'school', 'lawschool', 'helmet', 'poison', 'sunglasses', 'philosophy', 'brain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "92c6c73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'war': 0,\n",
       " 'politics': 0,\n",
       " 'fashion': 0,\n",
       " 'culture': 0,\n",
       " 'sport': 0,\n",
       " 'education': 0}"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories_dict = {key[0]: 0 for key in descriptive_keywords}\n",
    "categories_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "a71b4ea3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('study', (0.574546754360199, 'education')),\n",
       " ('follow', (0.43281760811805725, 'fashion')),\n",
       " ('study', (0.574546754360199, 'education')),\n",
       " ('earn', (0.4088855981826782, 'education')),\n",
       " ('rave', (0.32954198122024536, 'culture')),\n",
       " ('review', (0.4184594452381134, 'education')),\n",
       " ('award', (0.47735095024108887, 'education')),\n",
       " ('contract', (0.3552599549293518, 'education')),\n",
       " ('covent', (0.18027999997138977, 'fashion')),\n",
       " ('garden', (0.3839989900588989, 'fashion')),\n",
       " ('contract', (0.3552599549293518, 'education')),\n",
       " ('ground', (0.41804057359695435, 'war')),\n",
       " ('year', (0.49935826659202576, 'education')),\n",
       " ('return', (0.406259685754776, 'war')),\n",
       " ('rest', (0.4607382118701935, 'war')),\n",
       " ('life', (0.5718253254890442, 'culture'))]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_categories\n",
    "# similar_categories_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "a8b55cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('education', 7.327335357666016),\n",
      " ('war', 2.5700769424438477),\n",
      " ('fashion', 1.994193196296692),\n",
      " ('culture', 1.802734613418579),\n",
      " ('politics', 0),\n",
      " ('sport', 0)]\n",
      "\n",
      "The dominant category is: 'education'"
     ]
    }
   ],
   "source": [
    "for x in similar_categories:\n",
    "    categories_dict[x[1][1]] += x[1][0] #print(x[1])\n",
    "    \n",
    "categories_dict\n",
    "\n",
    "# sorted(categories_dict, key=lambda )\n",
    "results = list(sorted(categories_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "pprint(results)\n",
    "\n",
    "print(f\"\\nThe dominant category is: '{results[0][0]}'\", end='')\n",
    "if (results[0][1] - (float(results[0][1])/5)) <= results[1][1]:  \n",
    "    print(f\", closely followed by: '{results[1][0]}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "19719d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'war': 3.8231630325317383,\n",
       " 'politics': 0.46853357553482056,\n",
       " 'fashion': 1.8761795163154602,\n",
       " 'culture': 0.9031941294670105,\n",
       " 'sport': 4.09539407491684,\n",
       " 'education': 7.556927263736725}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x in similar_categories_extended:\n",
    "    #print(x)\n",
    "    for category in x[1]:\n",
    "        #print(category)\n",
    "        categories_dict[category[1]] += category[0]\n",
    "        # print(category)\n",
    "    #categories_dict[x[1]]\n",
    "    #print(x)\n",
    "\n",
    "categories_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "067c9f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['art',\n",
       " 'year',\n",
       " 'work',\n",
       " 'time',\n",
       " 'city',\n",
       " 'exhibition',\n",
       " 'world',\n",
       " 'opera',\n",
       " 'school',\n",
       " 'music',\n",
       " 'company',\n",
       " 'artist',\n",
       " 'gallery',\n",
       " 'film',\n",
       " 'member',\n",
       " 'museum',\n",
       " 'festival',\n",
       " 'war',\n",
       " 'society',\n",
       " 'painting']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d413c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7686a3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ec27fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce41bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f42946f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f95cbff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8846ea94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabd5567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78812c10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3241cceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba128ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8961126e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23853fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f2c76a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661bf6a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "54302003",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fasttext'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m      Traceback (most recent call last)",
      "Input \u001b[1;32mIn [69]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfasttext\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fasttext'"
     ]
    }
   ],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c981351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = map(float, tokens[1:])\n",
    "    return data\n",
    "\n",
    "vectors = load_vectors(\"../../../../cc.en.300.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "372b8655",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim.models.wrappers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m      Traceback (most recent call last)",
      "Input \u001b[1;32mIn [72]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastText\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gensim.models.wrappers'"
     ]
    }
   ],
   "source": [
    "from gensim.models.wrappers import FastText\n",
    "\n",
    "#model = FastText.load_fasttext_format('wiki.simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9c63bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fa0aad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 70\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Supervised fastText models are not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../../../cc.en.300.vec\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m model4 \u001b[38;5;241m=\u001b[39m \u001b[43mgensim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfasttext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_facebook_vectors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Personal Files [Local]\\Applied Data Science\\Thesis - CITYNET\\venv_citynet2\\lib\\site-packages\\gensim\\models\\fasttext.py:784\u001b[0m, in \u001b[0;36mload_facebook_vectors\u001b[1;34m(path, encoding)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_facebook_vectors\u001b[39m(path, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;124;03m\"\"\"Load word embeddings from a model saved in Facebook's native fasttext `.bin` format.\u001b[39;00m\n\u001b[0;32m    733\u001b[0m \n\u001b[0;32m    734\u001b[0m \u001b[38;5;124;03m    Notes\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    782\u001b[0m \n\u001b[0;32m    783\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 784\u001b[0m     full_model \u001b[38;5;241m=\u001b[39m \u001b[43m_load_fasttext_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m full_model\u001b[38;5;241m.\u001b[39mwv\n",
      "File \u001b[1;32m~\\Personal Files [Local]\\Applied Data Science\\Thesis - CITYNET\\venv_citynet2\\lib\\site-packages\\gensim\\models\\fasttext.py:808\u001b[0m, in \u001b[0;36m_load_fasttext_format\u001b[1;34m(model_file, encoding, full_model)\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[38;5;124;03m\"\"\"Load the input-hidden weight matrix from Facebook's native fasttext `.bin` output files.\u001b[39;00m\n\u001b[0;32m    790\u001b[0m \n\u001b[0;32m    791\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    805\u001b[0m \n\u001b[0;32m    806\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mopen(model_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fin:\n\u001b[1;32m--> 808\u001b[0m     m \u001b[38;5;241m=\u001b[39m \u001b[43mgensim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fasttext_bin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    810\u001b[0m model \u001b[38;5;241m=\u001b[39m FastText(\n\u001b[0;32m    811\u001b[0m     vector_size\u001b[38;5;241m=\u001b[39mm\u001b[38;5;241m.\u001b[39mdim,\n\u001b[0;32m    812\u001b[0m     window\u001b[38;5;241m=\u001b[39mm\u001b[38;5;241m.\u001b[39mws,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    821\u001b[0m     max_n\u001b[38;5;241m=\u001b[39mm\u001b[38;5;241m.\u001b[39mmaxn,\n\u001b[0;32m    822\u001b[0m )\n\u001b[0;32m    823\u001b[0m model\u001b[38;5;241m.\u001b[39mcorpus_total_words \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mntokens\n",
      "File \u001b[1;32m~\\Personal Files [Local]\\Applied Data Science\\Thesis - CITYNET\\venv_citynet2\\lib\\site-packages\\gensim\\models\\_fasttext_bin.py:345\u001b[0m, in \u001b[0;36mload\u001b[1;34m(fin, encoding, full_model)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_format:\n\u001b[0;32m    343\u001b[0m     model\u001b[38;5;241m.\u001b[39mupdate(dim\u001b[38;5;241m=\u001b[39mmagic, ws\u001b[38;5;241m=\u001b[39mversion)\n\u001b[1;32m--> 345\u001b[0m raw_vocab, vocab_size, nwords, ntokens \u001b[38;5;241m=\u001b[39m \u001b[43m_load_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    346\u001b[0m model\u001b[38;5;241m.\u001b[39mupdate(raw_vocab\u001b[38;5;241m=\u001b[39mraw_vocab, vocab_size\u001b[38;5;241m=\u001b[39mvocab_size, nwords\u001b[38;5;241m=\u001b[39mnwords, ntokens\u001b[38;5;241m=\u001b[39mntokens)\n\u001b[0;32m    348\u001b[0m vectors_ngrams \u001b[38;5;241m=\u001b[39m _load_matrix(fin, new_format\u001b[38;5;241m=\u001b[39mnew_format)\n",
      "File \u001b[1;32m~\\Personal Files [Local]\\Applied Data Science\\Thesis - CITYNET\\venv_citynet2\\lib\\site-packages\\gensim\\models\\_fasttext_bin.py:198\u001b[0m, in \u001b[0;36m_load_vocab\u001b[1;34m(fin, new_format, encoding)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# Vocab stored by [Dictionary::save](https://github.com/facebookresearch/fastText/blob/master/src/dictionary.cc)\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nlabels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupervised fastText models are not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    199\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m words for fastText model from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, vocab_size, fin\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m    201\u001b[0m ntokens \u001b[38;5;241m=\u001b[39m _struct_unpack(fin, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m@q\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# number of tokens\u001b[39;00m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Supervised fastText models are not supported"
     ]
    }
   ],
   "source": [
    "path = \"../../../../cc.en.300.vec\"\n",
    "model4 = gensim.models.fasttext.load_facebook_vectors(path)\n",
    "# model3 = gensim.models.fasttext.load_facebook_model(path, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9856fec4",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, '\\xba'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnpicklingError\u001b[0m          Traceback (most recent call last)",
      "Input \u001b[1;32mIn [68]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KeyedVectors, Word2Vec\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# wv_from_bin = KeyedVectors.load_word2vec_format(datapath(\"cc.en.300.bin\"), binary=True)  # C bin forma\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# word_vectors = KeyedVectors.load(\"../../../../cc.en.300.bin\")\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m word_vectors2 \u001b[38;5;241m=\u001b[39m \u001b[43mWord2Vec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../../../../cc.en.300.bin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Personal Files [Local]\\Applied Data Science\\Thesis - CITYNET\\venv_citynet2\\lib\\site-packages\\gensim\\models\\word2vec.py:1939\u001b[0m, in \u001b[0;36mWord2Vec.load\u001b[1;34m(cls, rethrow, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;124;03m\"\"\"Load a previously saved :class:`~gensim.models.word2vec.Word2Vec` model.\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \n\u001b[0;32m   1922\u001b[0m \u001b[38;5;124;03mSee Also\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1936\u001b[0m \n\u001b[0;32m   1937\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1938\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1939\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(Word2Vec, \u001b[38;5;28mcls\u001b[39m)\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1940\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, Word2Vec):\n\u001b[0;32m   1941\u001b[0m         rethrow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\Personal Files [Local]\\Applied Data Science\\Thesis - CITYNET\\venv_citynet2\\lib\\site-packages\\gensim\\utils.py:486\u001b[0m, in \u001b[0;36mSaveLoad.load\u001b[1;34m(cls, fname, mmap)\u001b[0m\n\u001b[0;32m    482\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m object from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, fname)\n\u001b[0;32m    484\u001b[0m compress, subname \u001b[38;5;241m=\u001b[39m SaveLoad\u001b[38;5;241m.\u001b[39m_adapt_by_suffix(fname)\n\u001b[1;32m--> 486\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[43munpickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    487\u001b[0m obj\u001b[38;5;241m.\u001b[39m_load_specials(fname, mmap, compress, subname)\n\u001b[0;32m    488\u001b[0m obj\u001b[38;5;241m.\u001b[39madd_lifecycle_event(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloaded\u001b[39m\u001b[38;5;124m\"\u001b[39m, fname\u001b[38;5;241m=\u001b[39mfname)\n",
      "File \u001b[1;32m~\\Personal Files [Local]\\Applied Data Science\\Thesis - CITYNET\\venv_citynet2\\lib\\site-packages\\gensim\\utils.py:1461\u001b[0m, in \u001b[0;36munpickle\u001b[1;34m(fname)\u001b[0m\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;124;03m\"\"\"Load object from `fname`, using smart_open so that `fname` can be on S3, HDFS, compressed etc.\u001b[39;00m\n\u001b[0;32m   1448\u001b[0m \n\u001b[0;32m   1449\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1458\u001b[0m \n\u001b[0;32m   1459\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1460\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fname, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m-> 1461\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_pickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlatin1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mUnpicklingError\u001b[0m: invalid load key, '\\xba'."
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim.models import KeyedVectors, Word2Vec\n",
    "\n",
    "# wv_from_bin = KeyedVectors.load_word2vec_format(datapath(\"cc.en.300.bin\"), binary=True)  # C bin forma\n",
    "# word_vectors = KeyedVectors.load(\"../../../../cc.en.300.bin\")\n",
    "word_vectors2 = Word2Vec.load(\"../../../../cc.en.300.bin\")\n",
    "# wv_from_bin.save(\"cc_en_300.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6df84b46",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'Word2Vec' has no attribute 'load_word2vec_format'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [60]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m word2vec\n\u001b[1;32m----> 2\u001b[0m model2 \u001b[38;5;241m=\u001b[39m \u001b[43mword2vec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWord2Vec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_word2vec_format\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..//..//..//..//cc.en.300.bin\u001b[39m\u001b[38;5;124m\"\u001b[39m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m model2\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcc_en_300.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'Word2Vec' has no attribute 'load_word2vec_format'"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "model2 = word2vec.Word2Vec.load_word2vec_format(\"..//..//..//..//cc.en.300.bin\", binary=True)\n",
    "model2.save(\"cc_en_300.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae4fd587",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# init model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m Lbl2Vec(keywords_list\u001b[38;5;241m=\u001b[39mdescriptive_keywords, tagged_documents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, doc2vec_model\u001b[38;5;241m=\u001b[39m\u001b[43md\u001b[49m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# train model\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mfit()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "# init model #pretrained_w2v_model\n",
    "model = Lbl2Vec(keywords_list=descriptive_keywords, tagged_documents=None, doc2vec_model=wv_from_bin)\n",
    "# train model\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ac0cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get similarity scores for each new document from trained model\n",
    "model.predict_new_docs(tagged_docs=tagged_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f9d74d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
